{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3l6X2svyxRwsSuUoARw/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SteffanBurnette/TensorFlow-/blob/Testing_out_regression_neural_network_for_predicting_direction_of_future_stock_price/Stock_price_analysis_test_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Goal: Create a Regression neureal network that will be able to predict the future price of a stock when given the following metrics:\n",
        "* **Opening Price** - The price that the security started the day as.\n",
        "* **High** - The highest price of the security for the day.\n",
        "* **Low** - The lowest price of the security for the day.\n",
        "* **Closing price** - The price of the security when the market closes.\n",
        "* **Trading Volume** - The total quantity of shares or contracts traded for a specified security.\n",
        "\n",
        "When preparing the data, I think it would be best to **normalize** it since i still want to keep the proper distributions intact, but the put all values within the same range so that the model can make more precise decisions.\n",
        "\n",
        "**Normalization** - Changing the values of the numerical columns in the dataset to a common scale, without distorting differences in the ranges of values.\n",
        "\n",
        "##Steps to take to train the network:\n",
        "1. Use a **pandas DataFrame** to load in the data (or yahoo finance API depending on what I find to be better).\n",
        "2. Properly define the **Features** and **Labels** so that I know what values to feed into the neural network and what value(s) I should be recieving.\n",
        "3. **Normalize** the dataset so that all numbers encompass the same range but keep the distribution difference (might not need to use the **OneHotEncoder** since there isnt a non numerical column and will only used the **MinMaxScaler** for data **Normalization**).\n",
        "4. Split the dataset up into **Training** and **Testing** datasets, so that the model doesnt just get use to solving the same problems( So that we **Generalize** the neural network).\n",
        "5. Test out different **Optimizers** (mainly **Stochastic Gradient Descent(SGD)** and **Adam**) and experiment with the learning rate(Find the optimal learning rate by plotting the **loss curve**).\n",
        "6. Test out different training lengths (**epochs**).\n",
        "7. Test out creating different amounts of **layers** and **Nuerons**(Maybe try out the **linear activation function** but most likely wont contribute anything to the project).\n",
        "8. Evlaute the performace of the model to keep track of improvement.\n",
        "9. Test the model to make future predictions (Maybe on older values where we know the outcome, then current values and compare them with the true values the next day (does **predictions**==**Actual Values**)).\n",
        "10. Save the model for use in future projects if everything works as expected.\n",
        "\n",
        "###The STONK that shall be analyzed is dodge boi TESLA"
      ],
      "metadata": {
        "id": "hSnyhZa8NN_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSJRKZ3FMRjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will Be working on 758 clolumns of tesla stock data ranging from the start date of october 15th 2015 to october 15th 2018; Three years of stock data\n",
        "\n",
        "**Columns: date, close, volume, open, high and low**"
      ],
      "metadata": {
        "id": "gFnyzG0UWV3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing the data\n",
        "tesla = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/tesla-stock-price.csv\")\n",
        "tesla.head()\n",
        "#Changes the volume column from string to float\n",
        "tesla[\"volume\"] = tesla[\"volume\"].str.replace(',', '').astype(float)\n",
        "\n",
        "#This will be the features that the model will take in\n",
        "tesla_X = tesla[[\"open\", \"high\", \"low\", \"volume\"]]\n",
        "print(tesla_X)\n",
        "\n",
        "#This will be the labels that the model will try to predict\n",
        "tesla_y = tesla[[\"close\"]]\n",
        "print(tesla_y)\n",
        "\n",
        "tesla_X_train, tesla_X_test, tesla_y_train, tesla_y_test = train_test_split(tesla_X, tesla_y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(tesla_X_train.dtypes)\n",
        "\n",
        "#Create the object that will normalize the data\n",
        "ct = MinMaxScaler()\n",
        "\n",
        "#Normalizes the training and testing data for the features and labels\n",
        "ct.fit(tesla_X_train)\n",
        "tesla_X_train_norm = ct.transform(tesla_X_train)\n",
        "\n",
        "ct.fit(tesla_X_test)\n",
        "tesla_X_test_norm = ct.transform(tesla_X_test)\n",
        "\n",
        "ct.fit(tesla_y_train)\n",
        "tesla_y_train_norm = ct.transform(tesla_y_train)\n",
        "\n",
        "ct.fit(tesla_y_test)\n",
        "tesla_y_test_norm = ct.transform(tesla_y_test)\n",
        "\n",
        "\n",
        "print(f\"this is the data {tesla_X_train_norm}\")\n",
        "print(f\"\\n this is the single point in data {tesla_X_train_norm[0]} and  the shape is {tesla_X_train_norm[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLsNCNXUihW",
        "outputId": "22aa1766-42b9-487f-fa45-47bf876d9c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       open      high       low      volume\n",
            "0    264.50  273.8800  262.2400   4787699.0\n",
            "1    259.06  263.2800  254.5367   6189026.0\n",
            "2    261.00  261.9900  252.0100   7189257.0\n",
            "3    257.53  262.2500  249.0300   8128184.0\n",
            "4    264.61  265.5100  247.7700  12781560.0\n",
            "..      ...       ...       ...         ...\n",
            "752  211.99  214.8100  208.8000   4177956.0\n",
            "753  227.72  228.6000  202.0000  14877020.0\n",
            "754  226.50  231.1500  224.9400   2506836.0\n",
            "755  223.04  230.4805  222.8700   4327574.0\n",
            "756  216.43  221.7300  213.7000   2835920.0\n",
            "\n",
            "[757 rows x 4 columns]\n",
            "      close\n",
            "0    270.49\n",
            "1    259.59\n",
            "2    258.78\n",
            "3    252.23\n",
            "4    256.88\n",
            "..      ...\n",
            "752  210.09\n",
            "753  213.03\n",
            "754  228.10\n",
            "755  227.01\n",
            "756  221.31\n",
            "\n",
            "[757 rows x 1 columns]\n",
            "open      float64\n",
            "high      float64\n",
            "low       float64\n",
            "volume    float64\n",
            "dtype: object\n",
            "this is the data [[0.76985718 0.79470678 0.79863077 0.24341806]\n",
            " [0.74575439 0.7360514  0.75286312 0.26537162]\n",
            " [0.45296067 0.43645585 0.46363521 0.08984735]\n",
            " ...\n",
            " [0.94397839 0.95158115 0.97206609 0.12770029]\n",
            " [0.47055694 0.44105864 0.46803026 0.13485639]\n",
            " [0.59517126 0.56695363 0.55940498 0.25019676]]\n",
            "\n",
            " this is the single point in data [0.76985718 0.79470678 0.79863077 0.24341806] and  the shape is (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I have prepared the data to be properly passed to the neural network its time to create the neural network and train the model to make predictions on the data."
      ],
      "metadata": {
        "id": "Uw7Z6-kVcviI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the Model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(tesla_X_train_norm, tesla_y_train_norm, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hre0-ROwdHCJ",
        "outputId": "5e581448-72e2-45ba-9cc1-c2799926c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 0.2213 - mae: 0.2213\n",
            "Epoch 2/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0571 - mae: 0.0571\n",
            "Epoch 3/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0698 - mae: 0.0698\n",
            "Epoch 4/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0730 - mae: 0.0730\n",
            "Epoch 5/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0676 - mae: 0.0676\n",
            "Epoch 6/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0679 - mae: 0.0679\n",
            "Epoch 7/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0698 - mae: 0.0698\n",
            "Epoch 8/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0691 - mae: 0.0691\n",
            "Epoch 9/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0659 - mae: 0.0659\n",
            "Epoch 10/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0693 - mae: 0.0693\n",
            "Epoch 11/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0673 - mae: 0.0673\n",
            "Epoch 12/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0637 - mae: 0.0637\n",
            "Epoch 13/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0628 - mae: 0.0628\n",
            "Epoch 14/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0602 - mae: 0.0602\n",
            "Epoch 15/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0646 - mae: 0.0646\n",
            "Epoch 16/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0619 - mae: 0.0619\n",
            "Epoch 17/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0633 - mae: 0.0633\n",
            "Epoch 18/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0606 - mae: 0.0606\n",
            "Epoch 19/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0597 - mae: 0.0597\n",
            "Epoch 20/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0583 - mae: 0.0583\n",
            "Epoch 21/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0545 - mae: 0.0545\n",
            "Epoch 22/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0568 - mae: 0.0568\n",
            "Epoch 23/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0557 - mae: 0.0557\n",
            "Epoch 24/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0544 - mae: 0.0544\n",
            "Epoch 25/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0551 - mae: 0.0551\n",
            "Epoch 26/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0530 - mae: 0.0530\n",
            "Epoch 27/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0544 - mae: 0.0544\n",
            "Epoch 28/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0520 - mae: 0.0520\n",
            "Epoch 29/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0517 - mae: 0.0517\n",
            "Epoch 30/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0511 - mae: 0.0511\n",
            "Epoch 31/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0513 - mae: 0.0513\n",
            "Epoch 32/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0500 - mae: 0.0500\n",
            "Epoch 33/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0507 - mae: 0.0507\n",
            "Epoch 34/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0480 - mae: 0.0480\n",
            "Epoch 35/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0461 - mae: 0.0461\n",
            "Epoch 36/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.0470\n",
            "Epoch 37/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0471 - mae: 0.0471\n",
            "Epoch 38/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.0475\n",
            "Epoch 39/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0454 - mae: 0.0454\n",
            "Epoch 40/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0460\n",
            "Epoch 41/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0426 - mae: 0.0426\n",
            "Epoch 42/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0441 - mae: 0.0441\n",
            "Epoch 43/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0416 - mae: 0.0416\n",
            "Epoch 44/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0423 - mae: 0.0423\n",
            "Epoch 45/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0430 - mae: 0.0430\n",
            "Epoch 46/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0415 - mae: 0.0415\n",
            "Epoch 47/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0425 - mae: 0.0425\n",
            "Epoch 48/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384\n",
            "Epoch 49/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0394 - mae: 0.0394\n",
            "Epoch 50/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0404 - mae: 0.0404\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0374 - mae: 0.0374\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0382 - mae: 0.0382\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0367 - mae: 0.0367\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.0397\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0361 - mae: 0.0361\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0376 - mae: 0.0376\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0364 - mae: 0.0364\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0372 - mae: 0.0372\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0349 - mae: 0.0349\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0381 - mae: 0.0381\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0357 - mae: 0.0357\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0352 - mae: 0.0352\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0345 - mae: 0.0345\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.0358\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0338 - mae: 0.0338\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0350 - mae: 0.0350\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.0312\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0349 - mae: 0.0349\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0320 - mae: 0.0320\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.0330\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0328 - mae: 0.0328\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0308 - mae: 0.0308\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0320 - mae: 0.0320\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.0307\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.0296\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0297 - mae: 0.0297\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0317 - mae: 0.0317\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0314 - mae: 0.0314\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.0302\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.0298\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.0312\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.0298\n",
            "Epoch 86/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.0278\n",
            "Epoch 87/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 88/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.0288\n",
            "Epoch 89/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 90/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.0291\n",
            "Epoch 91/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 92/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 93/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.0282\n",
            "Epoch 94/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.0260\n",
            "Epoch 95/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.0271\n",
            "Epoch 96/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.0265\n",
            "Epoch 97/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 98/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 99/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0271 - mae: 0.0271\n",
            "Epoch 100/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.0263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a495d8ea050>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now lets evaluate the models performance and have it perform predictions"
      ],
      "metadata": {
        "id": "0NNxiT7nd9XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the models performance\n",
        "model.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFGgXLM_eEsD",
        "outputId": "d42f427a-ab99-4332-9818-0118ed45e090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - mae: 0.0217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0216848012059927, 0.0216848012059927]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets perform a prediction with the model"
      ],
      "metadata": {
        "id": "P_WuorYDecBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = model.predict(tesla_X_test_norm)\n",
        "print(y_preds)\n",
        "#print(tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCq-GNmaegxj",
        "outputId": "2b1b6f70-06b0-4d9a-f690-16f44168f942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "[[0.44376698]\n",
            " [0.6141335 ]\n",
            " [0.8905855 ]\n",
            " [0.2351066 ]\n",
            " [0.38756248]\n",
            " [0.8247474 ]\n",
            " [0.63711995]\n",
            " [0.68583286]\n",
            " [0.8423107 ]\n",
            " [0.22538745]\n",
            " [0.7409962 ]\n",
            " [0.3481288 ]\n",
            " [0.31492582]\n",
            " [0.3261777 ]\n",
            " [0.6776508 ]\n",
            " [0.99387985]\n",
            " [0.90933526]\n",
            " [0.2890571 ]\n",
            " [0.6854939 ]\n",
            " [0.269133  ]\n",
            " [0.7555092 ]\n",
            " [0.10012738]\n",
            " [0.44200182]\n",
            " [0.85822046]\n",
            " [0.3035989 ]\n",
            " [0.4463897 ]\n",
            " [0.67094564]\n",
            " [0.73836815]\n",
            " [0.20183063]\n",
            " [0.8448958 ]\n",
            " [0.16108754]\n",
            " [0.45366567]\n",
            " [0.78488827]\n",
            " [0.5813505 ]\n",
            " [0.69832003]\n",
            " [0.26454967]\n",
            " [0.7190632 ]\n",
            " [0.31210026]\n",
            " [0.35872993]\n",
            " [0.36000645]\n",
            " [0.2565409 ]\n",
            " [0.63064843]\n",
            " [0.73057747]\n",
            " [0.8385634 ]\n",
            " [0.27514574]\n",
            " [0.4579083 ]\n",
            " [0.37953347]\n",
            " [0.73687047]\n",
            " [0.2803567 ]\n",
            " [0.3131518 ]\n",
            " [0.7008521 ]\n",
            " [0.29660222]\n",
            " [0.8656379 ]\n",
            " [0.25005305]\n",
            " [0.86088103]\n",
            " [0.16330558]\n",
            " [0.85126984]\n",
            " [0.23339973]\n",
            " [0.03227162]\n",
            " [0.7105383 ]\n",
            " [0.9018708 ]\n",
            " [0.92371565]\n",
            " [0.6726844 ]\n",
            " [0.27875146]\n",
            " [0.4486321 ]\n",
            " [0.505076  ]\n",
            " [0.82368535]\n",
            " [0.84391737]\n",
            " [0.2713715 ]\n",
            " [0.9488963 ]\n",
            " [0.713357  ]\n",
            " [0.3094337 ]\n",
            " [0.3603939 ]\n",
            " [0.7285354 ]\n",
            " [0.3536615 ]\n",
            " [0.87150115]\n",
            " [0.3334553 ]\n",
            " [0.7136829 ]\n",
            " [0.84533983]\n",
            " [0.89191854]\n",
            " [0.15800814]\n",
            " [0.7009621 ]\n",
            " [0.9483035 ]\n",
            " [0.6805338 ]\n",
            " [0.76530284]\n",
            " [0.7600469 ]\n",
            " [0.3823842 ]\n",
            " [0.1902038 ]\n",
            " [0.9595442 ]\n",
            " [0.76440746]\n",
            " [0.83659714]\n",
            " [0.5627809 ]\n",
            " [0.17801407]\n",
            " [0.7823346 ]\n",
            " [0.9212947 ]\n",
            " [0.5316233 ]\n",
            " [0.50142586]\n",
            " [0.6213544 ]\n",
            " [0.42627084]\n",
            " [0.275973  ]\n",
            " [0.6821475 ]\n",
            " [0.73197174]\n",
            " [0.36013487]\n",
            " [0.81336707]\n",
            " [0.79429066]\n",
            " [0.64316803]\n",
            " [0.8964796 ]\n",
            " [0.18726663]\n",
            " [0.47979492]\n",
            " [0.22454453]\n",
            " [0.32734704]\n",
            " [0.63857245]\n",
            " [0.44221628]\n",
            " [0.4016051 ]\n",
            " [0.315072  ]\n",
            " [0.84254646]\n",
            " [0.3236201 ]\n",
            " [0.4782255 ]\n",
            " [0.34005696]\n",
            " [0.43971464]\n",
            " [0.7689896 ]\n",
            " [0.30324897]\n",
            " [0.43138775]\n",
            " [0.86230874]\n",
            " [0.7237483 ]\n",
            " [0.82606274]\n",
            " [0.94925237]\n",
            " [0.94247377]\n",
            " [0.8102123 ]\n",
            " [0.29732037]\n",
            " [0.23571227]\n",
            " [0.22289258]\n",
            " [0.8526615 ]\n",
            " [0.67114246]\n",
            " [0.3659877 ]\n",
            " [0.6301971 ]\n",
            " [0.6977058 ]\n",
            " [0.7093064 ]\n",
            " [0.2197692 ]\n",
            " [1.0298835 ]\n",
            " [0.3476117 ]\n",
            " [0.9848505 ]\n",
            " [0.6663915 ]\n",
            " [0.98535746]\n",
            " [0.44965947]\n",
            " [0.38111624]\n",
            " [0.9508664 ]\n",
            " [0.75971484]\n",
            " [0.23463552]\n",
            " [0.7060465 ]\n",
            " [0.7550514 ]\n",
            " [0.77056795]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction are not quite the same as the true values even thought the mae metrioc is 0.02. Will create a new model with the adam optimizer to see if there is any improvement.\n",
        "\n",
        "Will also train the model for longer and leave the layers alone for this iteration."
      ],
      "metadata": {
        "id": "eCSCosCTgqqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the Model\n",
        "model_2.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "history_2 = model_2.fit(tesla_X_train_norm, tesla_y_train_norm, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNy2oGH7g816",
        "outputId": "f02de750-caad-4c5f-d75d-eab80760176a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 1.2727 - mae: 1.2727\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.2075 - mae: 0.2075\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1527 - mae: 0.1527\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0697 - mae: 0.0697\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0354 - mae: 0.0354\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0262 - mae: 0.0262\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0280 - mae: 0.0280\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.0254\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.0287\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0381 - mae: 0.0381\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0396 - mae: 0.0396\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0235 - mae: 0.0235\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0586 - mae: 0.0586\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0572 - mae: 0.0572\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0549 - mae: 0.0549\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0370 - mae: 0.0370\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0410 - mae: 0.0410\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.0412\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0448 - mae: 0.0448\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0485 - mae: 0.0485\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0418 - mae: 0.0418\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0427 - mae: 0.0427\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0262 - mae: 0.0262\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.0270\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0323 - mae: 0.0323\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.0267\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.0288\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.0253\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0185 - mae: 0.0185\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0169\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.0196\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0158\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0165\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.0185\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0199\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.0389\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.0274\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0316 - mae: 0.0316\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.0254\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0208 - mae: 0.0208\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0207\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0277 - mae: 0.0277\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0462 - mae: 0.0462\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.0403\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.0240\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0199\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.0244\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.0218\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0128\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0207\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0145\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0157 - mae: 0.0157\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.0233\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0197\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0173\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.0256\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0281\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.0326\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0309 - mae: 0.0309\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0580 - mae: 0.0580\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1865 - mae: 0.1865\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.2335 - mae: 0.2335\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.3039 - mae: 0.3039\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1840 - mae: 0.1840\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2983 - mae: 0.2983\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2778 - mae: 0.2778\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1576 - mae: 0.1576\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1888 - mae: 0.1888\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0996 - mae: 0.0996\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0877 - mae: 0.0877\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0690 - mae: 0.0690\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0607 - mae: 0.0607\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0563 - mae: 0.0563\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0213 - mae: 0.0213\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.0191\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.0266\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0142\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.0193\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0183\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.0255\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0146\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.0226\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.0215\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0186\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.0174\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0147\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0134\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.0166\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0248 - mae: 0.0248\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0229\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0182\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.0260\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0236 - mae: 0.0236\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0327 - mae: 0.0327\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0161\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.0213\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0139\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0127 - mae: 0.0127\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.0264\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0204 - mae: 0.0204\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.0235\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.0246\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0233 - mae: 0.0233\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0164\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0169\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.0191\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0190\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.0351\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0563 - mae: 0.0563\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.0411\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0597 - mae: 0.0597\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0697 - mae: 0.0697\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1497 - mae: 0.1497\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2422 - mae: 0.2422\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3245 - mae: 0.3245\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6365 - mae: 0.6365\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5483 - mae: 0.5483\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8376 - mae: 0.8376\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6303 - mae: 0.6303\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 3.0833 - mae: 3.0833\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 19.0230 - mae: 19.0230\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 15.2821 - mae: 15.2821\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 2.3267 - mae: 2.3267\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.4848 - mae: 1.4848\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5050 - mae: 0.5050\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2456 - mae: 0.2456\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0655 - mae: 0.0655\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.0492\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0430 - mae: 0.0430\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.0203\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0135\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.0184\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0153\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0120\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0151\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.0252\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.0331\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.0226\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0137\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0190\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.0313\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0228 - mae: 0.0228\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0160\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0224 - mae: 0.0224\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.0195\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.0180\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0136\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0205\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.0283\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0140\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0173\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juBs2GT2hTt3",
        "outputId": "de340740-f930-4a5d-b0e8-f01a55704282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012555108405649662, 0.012555108405649662]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_2 = model_2.predict(tesla_X_test_norm)\n",
        "#un-normalizes the output values\n",
        "y_preds_2_unnorm = ct.inverse_transform(model_2.predict(tesla_X_test_norm))\n",
        "#print(y_preds_2 == tesla_y_test_norm )\n",
        "print(y_preds_2_unnorm)\n",
        "print( tesla_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oBMl5n8hhLq",
        "outputId": "28442179-0f70-4cd8-ae48-99a95ddb6172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "[[252.64156]\n",
            " [293.9004 ]\n",
            " [351.95917]\n",
            " [205.13486]\n",
            " [240.53825]\n",
            " [337.1643 ]\n",
            " [297.21368]\n",
            " [304.79947]\n",
            " [335.00867]\n",
            " [201.25069]\n",
            " [323.58282]\n",
            " [233.67511]\n",
            " [222.38356]\n",
            " [225.71855]\n",
            " [306.83957]\n",
            " [376.20306]\n",
            " [360.81897]\n",
            " [216.04971]\n",
            " [306.13477]\n",
            " [212.97069]\n",
            " [325.78876]\n",
            " [174.17554]\n",
            " [253.34697]\n",
            " [344.38947]\n",
            " [218.98557]\n",
            " [252.82784]\n",
            " [306.84378]\n",
            " [318.06308]\n",
            " [196.91771]\n",
            " [344.83026]\n",
            " [189.33182]\n",
            " [253.3211 ]\n",
            " [330.919  ]\n",
            " [285.09018]\n",
            " [311.80948]\n",
            " [208.60725]\n",
            " [312.6906 ]\n",
            " [221.44257]\n",
            " [231.73349]\n",
            " [235.02457]\n",
            " [211.17877]\n",
            " [297.64706]\n",
            " [316.6948 ]\n",
            " [341.88522]\n",
            " [212.16408]\n",
            " [255.10878]\n",
            " [236.21388]\n",
            " [321.816  ]\n",
            " [213.75531]\n",
            " [212.06918]\n",
            " [309.33093]\n",
            " [219.39435]\n",
            " [348.35858]\n",
            " [209.19563]\n",
            " [350.06592]\n",
            " [189.71912]\n",
            " [345.77832]\n",
            " [204.512  ]\n",
            " [159.6236 ]\n",
            " [308.15704]\n",
            " [358.7288 ]\n",
            " [356.57065]\n",
            " [304.6649 ]\n",
            " [215.40062]\n",
            " [252.53099]\n",
            " [262.47818]\n",
            " [339.40237]\n",
            " [338.23822]\n",
            " [212.89348]\n",
            " [368.27896]\n",
            " [313.10358]\n",
            " [221.3158 ]\n",
            " [234.86057]\n",
            " [316.27158]\n",
            " [232.82678]\n",
            " [346.9583 ]\n",
            " [226.26358]\n",
            " [311.1795 ]\n",
            " [347.13565]\n",
            " [356.25598]\n",
            " [187.98401]\n",
            " [304.40442]\n",
            " [369.45026]\n",
            " [307.99612]\n",
            " [324.0246 ]\n",
            " [321.57   ]\n",
            " [237.45535]\n",
            " [194.81906]\n",
            " [378.721  ]\n",
            " [325.2577 ]\n",
            " [344.08902]\n",
            " [279.18097]\n",
            " [190.47816]\n",
            " [328.96823]\n",
            " [362.9121 ]\n",
            " [266.99942]\n",
            " [265.4577 ]\n",
            " [293.99768]\n",
            " [247.31693]\n",
            " [214.0454 ]\n",
            " [306.03812]\n",
            " [315.17142]\n",
            " [234.09383]\n",
            " [332.34744]\n",
            " [333.17212]\n",
            " [299.3249 ]\n",
            " [358.64816]\n",
            " [195.22032]\n",
            " [257.6188 ]\n",
            " [201.5722 ]\n",
            " [226.2629 ]\n",
            " [293.9816 ]\n",
            " [247.74338]\n",
            " [244.53476]\n",
            " [222.32153]\n",
            " [342.99567]\n",
            " [225.18704]\n",
            " [260.66956]\n",
            " [231.03697]\n",
            " [252.89482]\n",
            " [324.679  ]\n",
            " [220.52837]\n",
            " [251.75394]\n",
            " [342.5868 ]\n",
            " [314.94684]\n",
            " [343.29572]\n",
            " [372.29428]\n",
            " [365.9076 ]\n",
            " [337.52353]\n",
            " [218.22606]\n",
            " [203.19115]\n",
            " [202.78258]\n",
            " [343.64822]\n",
            " [302.09845]\n",
            " [236.18996]\n",
            " [291.42426]\n",
            " [309.81894]\n",
            " [312.2092 ]\n",
            " [203.27805]\n",
            " [386.6467 ]\n",
            " [230.01111]\n",
            " [373.8866 ]\n",
            " [300.8959 ]\n",
            " [374.55515]\n",
            " [255.52037]\n",
            " [236.61679]\n",
            " [361.61957]\n",
            " [328.08304]\n",
            " [206.2393 ]\n",
            " [313.8351 ]\n",
            " [324.72055]\n",
            " [326.3514 ]]\n",
            "      close\n",
            "409  251.57\n",
            "97   291.72\n",
            "281  349.59\n",
            "497  202.34\n",
            "440  238.36\n",
            "..      ...\n",
            "213  328.91\n",
            "501  203.56\n",
            "356  313.06\n",
            "90   317.66\n",
            "360  324.81\n",
            "\n",
            "[152 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inversing the predictions i realized that the predicted values are higher than the actual values by 2. After making this discovery i will make the bias more complex and try to remove any biases."
      ],
      "metadata": {
        "id": "-PB3CCitsnZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model, this time with more neurons and an activaton function\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"linear\") # Output layer for regression\n",
        "])\n",
        "\n",
        "#2. Compile the model, Will keep using adam with a learning rate of 0.01\n",
        "model_3.compile(loss= tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "#3. Fit the model to the normalized data\n",
        "model_3.fit(tesla_X_train_norm, tesla_y_train_norm, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTUlB6q_3tgx",
        "outputId": "ab37d76b-2b28-4bf2-bcce-31fe3661ff0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 0.0704 - mae: 0.0704\n",
            "Epoch 2/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.0212\n",
            "Epoch 3/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0167\n",
            "Epoch 4/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 5/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 6/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0327 - mae: 0.0327\n",
            "Epoch 7/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0225 - mae: 0.0225\n",
            "Epoch 8/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 9/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0211 - mae: 0.0211\n",
            "Epoch 10/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0161\n",
            "Epoch 11/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0148\n",
            "Epoch 12/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0140\n",
            "Epoch 13/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.0309\n",
            "Epoch 14/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.0282\n",
            "Epoch 15/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 16/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0183\n",
            "Epoch 17/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0130\n",
            "Epoch 18/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 19/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0127\n",
            "Epoch 20/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0141\n",
            "Epoch 21/100\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 22/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 23/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 24/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.0285\n",
            "Epoch 25/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.0181\n",
            "Epoch 26/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 27/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 28/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 29/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0128\n",
            "Epoch 30/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0119\n",
            "Epoch 31/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0160\n",
            "Epoch 32/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0172\n",
            "Epoch 33/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 34/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 35/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0167\n",
            "Epoch 36/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0135\n",
            "Epoch 37/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 38/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0133\n",
            "Epoch 39/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 40/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 41/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0148 - mae: 0.0148\n",
            "Epoch 42/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 43/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 44/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0122 - mae: 0.0122\n",
            "Epoch 45/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0136\n",
            "Epoch 46/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 47/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n",
            "Epoch 48/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 49/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0109\n",
            "Epoch 50/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0216 - mae: 0.0216\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0122\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0123\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0151\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.0194\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0158\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0112\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0141\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0130\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0145\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0150\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0107\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0106\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0103\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0131\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0117\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0105\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0111\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0186 - mae: 0.0186\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0115\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0118 - mae: 0.0118\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0104 - mae: 0.0104\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0134\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0129\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 86/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 87/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 88/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 89/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0103\n",
            "Epoch 90/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 91/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174\n",
            "Epoch 92/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0102\n",
            "Epoch 93/100\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108\n",
            "Epoch 94/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0125\n",
            "Epoch 95/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 96/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0105\n",
            "Epoch 97/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0110\n",
            "Epoch 98/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0107\n",
            "Epoch 99/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0109\n",
            "Epoch 100/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a495da58940>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "model_3.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_08xtjtr52BD",
        "outputId": "eac4ee5f-9956-40e1-a4ca-c0c7784b5a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012571744620800018, 0.012571744620800018]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_3_unnorm = ct.inverse_transform(model_3.predict(tesla_X_test_norm))\n",
        "\n",
        "print(y_preds_3_unnorm, tesla_y_test)"
      ],
      "metadata": {
        "id": "3WTLP95p6DJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Will see if the model works on current tesla stock data\n",
        "\n",
        "#open->high->low->volume\n",
        "\n",
        "# Initialize the scaler\n",
        "ctx = MinMaxScaler()\n",
        "\n",
        "# Assuming 'train_data' is your training data used to fit the model\n",
        "# It should be a NumPy array or similar structure with shape (num_samples, num_features)\n",
        "# ctx.fit(train_data)\n",
        "ctx.fit(tesla_X_train)\n",
        "# Your prediction data\n",
        "yfin = np.array([236.86, 240.12, 234.90, 92379400]).reshape(1, 4)\n",
        "\n",
        "# Normalize the prediction data using the already fitted scaler\n",
        "yfin_norm = ctx.transform(yfin)\n",
        "\n",
        "# Predict using the model\n",
        "current_pred_norm = model_3.predict(yfin_norm)\n",
        "\n",
        "# Inverse transform the prediction\n",
        "current_pred = ctx.inverse_transform(current_pred_norm)\n",
        "\n",
        "print(f\"This is the current prediction: {current_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "lFJkxqLUBMzJ",
        "outputId": "91f0d617-a97d-456b-c34e-163bafe12bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e49da9e7a0a4>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Inverse transform the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcurrent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_pred_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This is the current prediction: {current_pred}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.predict(tesla_X_test_norm[1])"
      ],
      "metadata": {
        "id": "JbnU3tZdFRa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Turns out that theres more to take into account were trying to forecast stock performance.\n",
        "The following code is from a tutorial on using Long Short term memory neural networks to predict microsoft stock prices to help gain a better understanding of what it takes to create a nueral network to analyze and predict future stock prices"
      ],
      "metadata": {
        "id": "2eB22viDkK4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "df = pd.read_csv(\"MSFT.csv\")\n",
        "#Discarding all other columns\n",
        "df = df[[\"Date\", \"Close\"]]\n",
        "\n",
        "#rightnow our date is a string so we will need to convert it\n",
        "#This is a function that converts the datetime values to int\n",
        "def str_to_datetime(s):\n",
        "  split = s.split('-')\n",
        "  year, month, day = int(split[0]), int(split[1]), int(split[2])\n",
        "  return datetime.datetime(year=year, month=month, day=day)\n",
        "\n",
        "\n",
        "#Will execute the function oin nevery column in the dataframe\n",
        "df[\"Date\"] = df[\"Date\"].apply(str_to_datetime)\n",
        "#Removes the date column and makes it the index\n",
        "df.index = df.pop(\"Date\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbjxnw0akmGy",
        "outputId": "1496cb6c-41a1-4393-bb0d-563c6a760419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Close\n",
            "Date                  \n",
            "1986-03-13    0.097222\n",
            "1986-03-14    0.100694\n",
            "1986-03-17    0.102431\n",
            "1986-03-18    0.099826\n",
            "1986-03-19    0.098090\n",
            "...                ...\n",
            "2023-12-29  376.040009\n",
            "2024-01-02  370.869995\n",
            "2024-01-03  370.600006\n",
            "2024-01-04  367.940002\n",
            "2024-01-05  367.750000\n",
            "\n",
            "[9531 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot to visdualize the current data\n",
        "plt.plot(df.index, df[\"Close\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "CTkO1GVcoYA1",
        "outputId": "9184dcee-613f-4175-f44d-796b7cf267b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a4959b058a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are using **LSTM** we need to convert this into a supervised problem."
      ],
      "metadata": {
        "id": "gw-uD-yloqj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
        "  first_date = str_to_datetime(first_date_str)\n",
        "  last_date  = str_to_datetime(last_date_str)\n",
        "\n",
        "  target_date = first_date\n",
        "\n",
        "  dates = []\n",
        "  X, Y = [], []\n",
        "\n",
        "  last_time = False\n",
        "  while True:\n",
        "    df_subset = dataframe.loc[:target_date].tail(n+1)\n",
        "\n",
        "    if len(df_subset) != n+1:\n",
        "      print(f'Error: Window of size {n} is too large for date {target_date}')\n",
        "      return\n",
        "\n",
        "    values = df_subset['Close'].to_numpy()\n",
        "    x, y = values[:-1], values[-1]\n",
        "\n",
        "    dates.append(target_date)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "    next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
        "    next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
        "    next_date_str = next_datetime_str.split('T')[0]\n",
        "    year_month_day = next_date_str.split('-')\n",
        "    year, month, day = year_month_day\n",
        "    next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
        "\n",
        "    if last_time:\n",
        "      break\n",
        "\n",
        "    target_date = next_date\n",
        "\n",
        "    if target_date == last_date:\n",
        "      last_time = True\n",
        "\n",
        "  ret_df = pd.DataFrame({})\n",
        "  ret_df['Target Date'] = dates\n",
        "\n",
        "  X = np.array(X)\n",
        "  for i in range(0, n):\n",
        "    X[:, i]\n",
        "    ret_df[f'Target-{n-i}'] = X[:, i]\n",
        "\n",
        "  ret_df['Target'] = Y\n",
        "\n",
        "  return ret_df\n",
        "\n",
        "# Start day second time around: '2021-03-25'\n",
        "windowed_df = df_to_windowed_df(df,\n",
        "                                '2021-03-25',\n",
        "                                '2022-03-23',\n",
        "                                n=3)\n",
        "windowed_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XnWkezsDoxPK",
        "outputId": "b19413cf-7aef-4901-93f7-33dcb7a298e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Target Date    Target-3    Target-2    Target-1      Target\n",
              "0    2021-03-25  235.990005  237.580002  235.460007  232.339996\n",
              "1    2021-03-26  237.580002  235.460007  232.339996  236.479996\n",
              "2    2021-03-29  235.460007  232.339996  236.479996  235.240005\n",
              "3    2021-03-30  232.339996  236.479996  235.240005  231.850006\n",
              "4    2021-03-31  236.479996  235.240005  231.850006  235.770004\n",
              "..          ...         ...         ...         ...         ...\n",
              "247  2022-03-17  276.440002  287.149994  294.390015  295.220001\n",
              "248  2022-03-18  287.149994  294.390015  295.220001  300.429993\n",
              "249  2022-03-21  294.390015  295.220001  300.429993  299.160004\n",
              "250  2022-03-22  295.220001  300.429993  299.160004  304.059998\n",
              "251  2022-03-23  300.429993  299.160004  304.059998  299.489990\n",
              "\n",
              "[252 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cc95884-87ce-446e-bae7-911ecd1c5a27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Date</th>\n",
              "      <th>Target-3</th>\n",
              "      <th>Target-2</th>\n",
              "      <th>Target-1</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-03-25</td>\n",
              "      <td>235.990005</td>\n",
              "      <td>237.580002</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-03-26</td>\n",
              "      <td>237.580002</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-03-30</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "      <td>231.850006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "      <td>231.850006</td>\n",
              "      <td>235.770004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2022-03-17</td>\n",
              "      <td>276.440002</td>\n",
              "      <td>287.149994</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>2022-03-18</td>\n",
              "      <td>287.149994</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2022-03-22</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "      <td>304.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>2022-03-23</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "      <td>304.059998</td>\n",
              "      <td>299.489990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>252 rows  5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cc95884-87ce-446e-bae7-911ecd1c5a27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cc95884-87ce-446e-bae7-911ecd1c5a27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cc95884-87ce-446e-bae7-911ecd1c5a27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-702305b6-b291-4183-b9ab-5d41156ee70e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-702305b6-b291-4183-b9ab-5d41156ee70e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-702305b6-b291-4183-b9ab-5d41156ee70e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_11623b7e-2b58-44a7-90ca-3ec3e24484e0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('windowed_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_11623b7e-2b58-44a7-90ca-3ec3e24484e0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('windowed_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Here are a couple of notable issue with my current approch to this task:\n",
        "* I am trying to predict a **specific price**. I should try to predict the overall movement of the stock(i.e. is it more likely to close on a high or a low) rather than trying to predict the its **closing price**.\n",
        "* I am using a **`Dense layer`** with a **linear activation function** as the final layer. After some consideration I might use a **sigmoid activation function** since I am trying to predict one of two things(high or low trajectory).\n",
        "* I did not take advantage of the **LSTM layer** which accels in handling sequential data and taking note of the most important patterns in data while dicarding the rest(**Dimensionality Reduction**).\n",
        "* Since the only **scaler** I am familiar with is a `MinMaxScaler` I used it to **normalize** the datas which intuitively does not make sense in this context since the stock price has no theoretical maximum. I should look into using dofferent **normalization techniques** such as:\n",
        "\n",
        "-**Percentage Change**- Instead of **normalizing** raw prices, you can convert prices to percentage changes or returns which are more stationary and typically has a more consistent range.\n",
        "\n",
        "-**Z-Score Normalizzation**- This method does not require a predefined `min` and `max`. It **normalizes** the data based on the **mean** and **standard deviation** of the dataset.\n",
        "\n",
        "*  Only looked at hard numbers and did not take into account things such as using **sentimental analysis** to analyze news articles and white papers/balance sheets on the companies finanicals, economic influences and various other things."
      ],
      "metadata": {
        "id": "3kvZuzk6qkEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First experiment: Long Short Term Memory\n",
        "When conducting the experiments before, I only used a **fully connected** model architecture. This time, I will take advantage of the **LSTM** layers since I will be handling long sequence data.\n",
        "\n",
        "On top of this I will develop **pipelines** for the preprocessing of the data so that I can efficient preprocess the data of various different stock's while adhering to the **DRY**(Don't Repeat Yourself) principle.\n",
        "\n",
        "Lastly, I will create functions to analyze the model's performance via various metrics.\n",
        "\n",
        "I will be taking advantage of yfinace API (and maybe googlefinance API) to get real time market data."
      ],
      "metadata": {
        "id": "QT7DiX95kcYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDf5GCcgsxpg",
        "outputId": "95d1757b-ac36-432d-8330-a40313e0f57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.37)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.0)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import random"
      ],
      "metadata": {
        "id": "YjK52AJnsDqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msft = yf.Ticker(\"MSFT\")\n",
        "\n",
        "# get historical market data\n",
        "hist = msft.history(period=\"10y\")\n",
        "hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nzunfyFqtF-0",
        "outputId": "d414083d-dc0f-4257-cfe2-4d98871ce7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2014-03-24 00:00:00-04:00   34.160105   34.414145   33.753639   34.295593   \n",
              "2014-03-25 00:00:00-04:00   34.431080   34.710527   33.838316   34.160103   \n",
              "2014-03-26 00:00:00-04:00   34.278649   34.473414   33.533460   33.694355   \n",
              "2014-03-27 00:00:00-04:00   33.652021   33.846786   33.313298   33.330235   \n",
              "2014-03-28 00:00:00-04:00   33.694367   34.414150   33.601218   34.126236   \n",
              "...                               ...         ...         ...         ...   \n",
              "2024-03-18 00:00:00-04:00  414.250000  420.730011  413.779999  417.320007   \n",
              "2024-03-19 00:00:00-04:00  417.829987  421.670013  415.549988  421.410004   \n",
              "2024-03-20 00:00:00-04:00  422.000000  425.959991  420.660004  425.230011   \n",
              "2024-03-21 00:00:00-04:00  429.829987  430.820007  427.160004  429.369995   \n",
              "2024-03-22 00:00:00-04:00  429.700012  429.859985  426.070007  428.739990   \n",
              "\n",
              "                             Volume  Dividends  Stock Splits  \n",
              "Date                                                          \n",
              "2014-03-24 00:00:00-04:00  46098400        0.0           0.0  \n",
              "2014-03-25 00:00:00-04:00  43193100        0.0           0.0  \n",
              "2014-03-26 00:00:00-04:00  41977500        0.0           0.0  \n",
              "2014-03-27 00:00:00-04:00  35369200        0.0           0.0  \n",
              "2014-03-28 00:00:00-04:00  43472700        0.0           0.0  \n",
              "...                             ...        ...           ...  \n",
              "2024-03-18 00:00:00-04:00  20106000        0.0           0.0  \n",
              "2024-03-19 00:00:00-04:00  19837900        0.0           0.0  \n",
              "2024-03-20 00:00:00-04:00  17860100        0.0           0.0  \n",
              "2024-03-21 00:00:00-04:00  21296200        0.0           0.0  \n",
              "2024-03-22 00:00:00-04:00  17636500        0.0           0.0  \n",
              "\n",
              "[2518 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5334a450-1f0d-4334-b311-a9b0be14f306\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-03-24 00:00:00-04:00</th>\n",
              "      <td>34.160105</td>\n",
              "      <td>34.414145</td>\n",
              "      <td>33.753639</td>\n",
              "      <td>34.295593</td>\n",
              "      <td>46098400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-25 00:00:00-04:00</th>\n",
              "      <td>34.431080</td>\n",
              "      <td>34.710527</td>\n",
              "      <td>33.838316</td>\n",
              "      <td>34.160103</td>\n",
              "      <td>43193100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-26 00:00:00-04:00</th>\n",
              "      <td>34.278649</td>\n",
              "      <td>34.473414</td>\n",
              "      <td>33.533460</td>\n",
              "      <td>33.694355</td>\n",
              "      <td>41977500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-27 00:00:00-04:00</th>\n",
              "      <td>33.652021</td>\n",
              "      <td>33.846786</td>\n",
              "      <td>33.313298</td>\n",
              "      <td>33.330235</td>\n",
              "      <td>35369200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-28 00:00:00-04:00</th>\n",
              "      <td>33.694367</td>\n",
              "      <td>34.414150</td>\n",
              "      <td>33.601218</td>\n",
              "      <td>34.126236</td>\n",
              "      <td>43472700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-18 00:00:00-04:00</th>\n",
              "      <td>414.250000</td>\n",
              "      <td>420.730011</td>\n",
              "      <td>413.779999</td>\n",
              "      <td>417.320007</td>\n",
              "      <td>20106000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-19 00:00:00-04:00</th>\n",
              "      <td>417.829987</td>\n",
              "      <td>421.670013</td>\n",
              "      <td>415.549988</td>\n",
              "      <td>421.410004</td>\n",
              "      <td>19837900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-20 00:00:00-04:00</th>\n",
              "      <td>422.000000</td>\n",
              "      <td>425.959991</td>\n",
              "      <td>420.660004</td>\n",
              "      <td>425.230011</td>\n",
              "      <td>17860100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-21 00:00:00-04:00</th>\n",
              "      <td>429.829987</td>\n",
              "      <td>430.820007</td>\n",
              "      <td>427.160004</td>\n",
              "      <td>429.369995</td>\n",
              "      <td>21296200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-22 00:00:00-04:00</th>\n",
              "      <td>429.700012</td>\n",
              "      <td>429.859985</td>\n",
              "      <td>426.070007</td>\n",
              "      <td>428.739990</td>\n",
              "      <td>17636500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2518 rows  7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5334a450-1f0d-4334-b311-a9b0be14f306')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5334a450-1f0d-4334-b311-a9b0be14f306 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5334a450-1f0d-4334-b311-a9b0be14f306');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ce557226-3b8b-490c-83fd-877c28e54e75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ce557226-3b8b-490c-83fd-877c28e54e75')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ce557226-3b8b-490c-83fd-877c28e54e75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_809d045c-0c54-4dc0-8f0c-237ae69cd0db\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('hist')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_809d045c-0c54-4dc0-8f0c-237ae69cd0db button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('hist');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "hist",
              "summary": "{\n  \"name\": \"hist\",\n  \"rows\": 2518,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-03-24 00:00:00-04:00\",\n        \"max\": \"2024-03-22 00:00:00-04:00\",\n        \"num_unique_values\": 2518,\n        \"samples\": [\n          \"2022-12-09 00:00:00-05:00\",\n          \"2015-11-05 00:00:00-05:00\",\n          \"2019-09-27 00:00:00-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.84882279046434,\n        \"min\": 33.025399696808904,\n        \"max\": 429.8299865722656,\n        \"num_unique_values\": 2516,\n        \"samples\": [\n          52.205772399902344,\n          77.62118664910174,\n          81.17102645331083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 108.91292696472334,\n        \"min\": 33.32176952915646,\n        \"max\": 430.82000732421875,\n        \"num_unique_values\": 2514,\n        \"samples\": [\n          52.32345884309904,\n          79.12125886335426,\n          80.40701873743596\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.75142602554614,\n        \"min\": 32.61045772230802,\n        \"max\": 427.1600036621094,\n        \"num_unique_values\": 2516,\n        \"samples\": [\n          51.60830746349421,\n          78.282701174552,\n          79.44735845207522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.89858189160995,\n        \"min\": 33.07619857788086,\n        \"max\": 429.3699951171875,\n        \"num_unique_values\": 2435,\n        \"samples\": [\n          241.77513122558594,\n          88.05816650390625,\n          203.7832489013672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13724735,\n        \"min\": 7425600,\n        \"max\": 202522400,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          31021900,\n          52433000,\n          49743700\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dividends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06264932611099823,\n        \"min\": 0.0,\n        \"max\": 0.75,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.68,\n          0.62,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock Splits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all stock info\n",
        "msft.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ8T7NactHbS",
        "outputId": "95a76fe3-bf8c-4607-8fc6-17df06d634a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'address1': 'One Microsoft Way',\n",
              " 'city': 'Redmond',\n",
              " 'state': 'WA',\n",
              " 'zip': '98052-6399',\n",
              " 'country': 'United States',\n",
              " 'phone': '425 882 8080',\n",
              " 'website': 'https://www.microsoft.com',\n",
              " 'industry': 'Software - Infrastructure',\n",
              " 'industryKey': 'software-infrastructure',\n",
              " 'industryDisp': 'Software - Infrastructure',\n",
              " 'sector': 'Technology',\n",
              " 'sectorKey': 'technology',\n",
              " 'sectorDisp': 'Technology',\n",
              " 'longBusinessSummary': 'Microsoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services. This segment also provides LinkedIn; and dynamics business solutions, including Dynamics 365, a set of intelligent, cloud-based applications across ERP, CRM, power apps, and power automate; and on-premises ERP and CRM applications. The Intelligent Cloud segment offers server products and cloud services, such as azure and other cloud services; SQL and windows server, visual studio, system center, and related client access licenses, as well as nuance and GitHub; and enterprise services including enterprise support services, industry solutions, and nuance professional services. The More Personal Computing segment offers Windows, including windows OEM licensing and other non-volume licensing of the Windows operating system; Windows commercial comprising volume licensing of the Windows operating system, windows cloud services, and other Windows commercial offerings; patent licensing; and windows Internet of Things; and devices, such as surface, HoloLens, and PC accessories. Additionally, this segment provides gaming, which includes Xbox hardware and content, and first- and third-party content; Xbox game pass and other subscriptions, cloud gaming, advertising, third-party disc royalties, and other cloud services; and search and news advertising, which includes Bing, Microsoft News and Edge, and third-party affiliates. The company sells its products through OEMs, distributors, and resellers; and directly through digital marketplaces, online, and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.',\n",
              " 'fullTimeEmployees': 221000,\n",
              " 'companyOfficers': [{'maxAge': 1,\n",
              "   'name': 'Mr. Satya  Nadella',\n",
              "   'age': 56,\n",
              "   'title': 'Chairman & CEO',\n",
              "   'yearBorn': 1967,\n",
              "   'fiscalYear': 2023,\n",
              "   'totalPay': 9276400,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Bradford L. Smith LCA',\n",
              "   'age': 64,\n",
              "   'title': 'President & Vice Chairman',\n",
              "   'yearBorn': 1959,\n",
              "   'fiscalYear': 2023,\n",
              "   'totalPay': 3591277,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Ms. Amy E. Hood',\n",
              "   'age': 51,\n",
              "   'title': 'Executive VP & CFO',\n",
              "   'yearBorn': 1972,\n",
              "   'fiscalYear': 2023,\n",
              "   'totalPay': 3452196,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Judson B. Althoff',\n",
              "   'age': 49,\n",
              "   'title': 'Executive VP & Chief Commercial Officer',\n",
              "   'yearBorn': 1974,\n",
              "   'fiscalYear': 2023,\n",
              "   'totalPay': 3355797,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Christopher David Young',\n",
              "   'age': 51,\n",
              "   'title': 'Executive Vice President of Business Development, Strategy & Ventures',\n",
              "   'yearBorn': 1972,\n",
              "   'fiscalYear': 2023,\n",
              "   'totalPay': 2460507,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Ms. Alice L. Jolla',\n",
              "   'age': 56,\n",
              "   'title': 'Corporate VP & Chief Accounting Officer',\n",
              "   'yearBorn': 1967,\n",
              "   'fiscalYear': 2023,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. James Kevin Scott',\n",
              "   'age': 51,\n",
              "   'title': 'Executive VP of AI & CTO',\n",
              "   'yearBorn': 1972,\n",
              "   'fiscalYear': 2023,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Brett  Iversen',\n",
              "   'title': 'Vice President of Investor Relations',\n",
              "   'fiscalYear': 2023,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Hossein  Nowbar',\n",
              "   'title': 'Chief Legal Officer',\n",
              "   'fiscalYear': 2023,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Frank X. Shaw',\n",
              "   'title': 'Chief Communications Officer',\n",
              "   'fiscalYear': 2023,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0}],\n",
              " 'auditRisk': 2,\n",
              " 'boardRisk': 5,\n",
              " 'compensationRisk': 2,\n",
              " 'shareHolderRightsRisk': 2,\n",
              " 'overallRisk': 1,\n",
              " 'governanceEpochDate': 1709251200,\n",
              " 'compensationAsOfEpochDate': 1703980800,\n",
              " 'maxAge': 86400,\n",
              " 'priceHint': 2,\n",
              " 'previousClose': 429.37,\n",
              " 'open': 429.69,\n",
              " 'dayLow': 426.07,\n",
              " 'dayHigh': 429.86,\n",
              " 'regularMarketPreviousClose': 429.37,\n",
              " 'regularMarketOpen': 429.69,\n",
              " 'regularMarketDayLow': 426.07,\n",
              " 'regularMarketDayHigh': 429.86,\n",
              " 'dividendRate': 3.0,\n",
              " 'dividendYield': 0.0069999998,\n",
              " 'exDividendDate': 1715731200,\n",
              " 'payoutRatio': 0.2523,\n",
              " 'fiveYearAvgDividendYield': 0.97,\n",
              " 'beta': 0.89,\n",
              " 'trailingPE': 38.8,\n",
              " 'forwardPE': 32.067314,\n",
              " 'volume': 17236095,\n",
              " 'regularMarketVolume': 17236095,\n",
              " 'averageVolume': 22724444,\n",
              " 'averageVolume10days': 23163750,\n",
              " 'averageDailyVolume10Day': 23163750,\n",
              " 'bid': 428.76,\n",
              " 'ask': 428.94,\n",
              " 'bidSize': 100,\n",
              " 'askSize': 100,\n",
              " 'marketCap': 3185726717952,\n",
              " 'fiftyTwoWeekLow': 272.05,\n",
              " 'fiftyTwoWeekHigh': 430.82,\n",
              " 'priceToSalesTrailing12Months': 13.998087,\n",
              " 'fiftyDayAverage': 407.941,\n",
              " 'twoHundredDayAverage': 359.69626,\n",
              " 'trailingAnnualDividendRate': 2.86,\n",
              " 'trailingAnnualDividendYield': 0.0066609215,\n",
              " 'currency': 'USD',\n",
              " 'enterpriseValue': 3216101343232,\n",
              " 'profitMargins': 0.36269,\n",
              " 'floatShares': 7418919053,\n",
              " 'sharesOutstanding': 7430439936,\n",
              " 'sharesShort': 48235867,\n",
              " 'sharesShortPriorMonth': 49875453,\n",
              " 'sharesShortPreviousMonthDate': 1706659200,\n",
              " 'dateShortInterest': 1709164800,\n",
              " 'sharesPercentSharesOut': 0.0064999997,\n",
              " 'heldPercentInsiders': 0.00054000004,\n",
              " 'heldPercentInstitutions': 0.73861,\n",
              " 'shortRatio': 2.02,\n",
              " 'shortPercentOfFloat': 0.0064999997,\n",
              " 'impliedSharesOutstanding': 7446219776,\n",
              " 'bookValue': 32.06,\n",
              " 'priceToBook': 13.37305,\n",
              " 'lastFiscalYearEnd': 1688083200,\n",
              " 'nextFiscalYearEnd': 1719705600,\n",
              " 'mostRecentQuarter': 1703980800,\n",
              " 'earningsQuarterlyGrowth': 0.332,\n",
              " 'netIncomeToCommon': 82541002752,\n",
              " 'trailingEps': 11.05,\n",
              " 'forwardEps': 13.37,\n",
              " 'pegRatio': 2.26,\n",
              " 'lastSplitFactor': '2:1',\n",
              " 'lastSplitDate': 1045526400,\n",
              " 'enterpriseToRevenue': 14.132,\n",
              " 'enterpriseToEbitda': 27.157,\n",
              " '52WeekChange': 0.55127,\n",
              " 'SandP52WeekChange': 0.31593728,\n",
              " 'lastDividendValue': 0.75,\n",
              " 'lastDividendDate': 1707868800,\n",
              " 'exchange': 'NMS',\n",
              " 'quoteType': 'EQUITY',\n",
              " 'symbol': 'MSFT',\n",
              " 'underlyingSymbol': 'MSFT',\n",
              " 'shortName': 'Microsoft Corporation',\n",
              " 'longName': 'Microsoft Corporation',\n",
              " 'firstTradeDateEpochUtc': 511108200,\n",
              " 'timeZoneFullName': 'America/New_York',\n",
              " 'timeZoneShortName': 'EDT',\n",
              " 'uuid': 'b004b3ec-de24-385e-b2c1-923f10d3fb62',\n",
              " 'messageBoardId': 'finmb_21835',\n",
              " 'gmtOffSetMilliseconds': -14400000,\n",
              " 'currentPrice': 428.74,\n",
              " 'targetHighPrice': 546.44,\n",
              " 'targetLowPrice': 298.1,\n",
              " 'targetMeanPrice': 457.5,\n",
              " 'targetMedianPrice': 457.5,\n",
              " 'recommendationMean': 1.7,\n",
              " 'recommendationKey': 'buy',\n",
              " 'numberOfAnalystOpinions': 48,\n",
              " 'totalCash': 80981999616,\n",
              " 'totalCashPerShare': 10.899,\n",
              " 'ebitda': 118427000832,\n",
              " 'totalDebt': 111358001152,\n",
              " 'quickRatio': 1.096,\n",
              " 'currentRatio': 1.218,\n",
              " 'totalRevenue': 227583000576,\n",
              " 'debtToEquity': 46.736,\n",
              " 'revenuePerShare': 30.612,\n",
              " 'returnOnAssets': 0.1519,\n",
              " 'returnOnEquity': 0.39174,\n",
              " 'freeCashflow': 58680999936,\n",
              " 'operatingCashflow': 102646996992,\n",
              " 'earningsGrowth': 0.332,\n",
              " 'revenueGrowth': 0.176,\n",
              " 'grossMargins': 0.69815004,\n",
              " 'ebitdaMargins': 0.52037,\n",
              " 'operatingMargins': 0.43585998,\n",
              " 'financialCurrency': 'USD',\n",
              " 'trailingPegRatio': 2.173}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "The stock that I will be analyzing is a concatenation of tech stocks to increase my dataset with historical financial data.I will make sure that they are all within the 10 year period so that there are no outlier dates. I will load the data into a dataframe and plot various visualizations of the distributions."
      ],
      "metadata": {
        "id": "pZcn6UX1uRZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOG = yf.Ticker(\"GOOG\")\n",
        "\n",
        "GOOG.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96aHdjGLuQ7n",
        "outputId": "e43a783e-4903-4fe6-8b80-28c9e6eeac94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'address1': '1600 Amphitheatre Parkway',\n",
              " 'city': 'Mountain View',\n",
              " 'state': 'CA',\n",
              " 'zip': '94043',\n",
              " 'country': 'United States',\n",
              " 'phone': '650 253 0000',\n",
              " 'website': 'https://abc.xyz',\n",
              " 'industry': 'Internet Content & Information',\n",
              " 'industryKey': 'internet-content-information',\n",
              " 'industryDisp': 'Internet Content & Information',\n",
              " 'sector': 'Communication Services',\n",
              " 'sectorKey': 'communication-services',\n",
              " 'sectorDisp': 'Communication Services',\n",
              " 'longBusinessSummary': 'Alphabet Inc. offers various products and platforms in the United States, Europe, the Middle East, Africa, the Asia-Pacific, Canada, and Latin America. It operates through Google Services, Google Cloud, and Other Bets segments. The Google Services segment provides products and services, including ads, Android, Chrome, devices, Gmail, Google Drive, Google Maps, Google Photos, Google Play, Search, and YouTube. It is also involved in the sale of apps and in-app purchases and digital content in the Google Play and YouTube; and devices, as well as in the provision of YouTube consumer subscription services. The Google Cloud segment offers infrastructure, cybersecurity, databases, analytics, AI, and other services; Google Workspace that include cloud-based communication and collaboration tools for enterprises, such as Gmail, Docs, Drive, Calendar, and Meet; and other services for enterprise customers. The Other Bets segment sells healthcare-related and internet services. The company was incorporated in 1998 and is headquartered in Mountain View, California.',\n",
              " 'fullTimeEmployees': 182502,\n",
              " 'companyOfficers': [{'maxAge': 1,\n",
              "   'name': 'Mr. Sundar  Pichai',\n",
              "   'age': 50,\n",
              "   'title': 'CEO & Director',\n",
              "   'yearBorn': 1973,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 7947461,\n",
              "   'exercisedValue': 39618220,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Ms. Ruth M. Porat',\n",
              "   'age': 65,\n",
              "   'title': 'President, Chief Investment Officer, Senior VP & CFO',\n",
              "   'yearBorn': 1958,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1790046,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Lawrence Edward Page',\n",
              "   'age': 50,\n",
              "   'title': 'Co-Founder & Director',\n",
              "   'yearBorn': 1973,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Sergey  Brin',\n",
              "   'age': 49,\n",
              "   'title': 'Co-Founder & Director',\n",
              "   'yearBorn': 1974,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. J. Kent Walker',\n",
              "   'age': 62,\n",
              "   'title': 'President of Global Affairs, Chief Legal Officer & Company Secretary',\n",
              "   'yearBorn': 1961,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1787541,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Dr. Prabhakar  Raghavan',\n",
              "   'age': 62,\n",
              "   'title': 'Senior Vice President of Knowledge and Information - Google',\n",
              "   'yearBorn': 1961,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1785329,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Mr. Philipp  Schindler',\n",
              "   'age': 51,\n",
              "   'title': 'Senior Vice President & Chief Business Officer of Google',\n",
              "   'yearBorn': 1972,\n",
              "   'fiscalYear': 2022,\n",
              "   'totalPay': 1785814,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': \"Ms. Amie Thuener O'Toole\",\n",
              "   'age': 47,\n",
              "   'title': 'Chief Accounting Officer & VP',\n",
              "   'yearBorn': 1976,\n",
              "   'fiscalYear': 2022,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Ms. Ellen  West',\n",
              "   'title': 'Vice President of Investor Relations',\n",
              "   'fiscalYear': 2022,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0},\n",
              "  {'maxAge': 1,\n",
              "   'name': 'Ms. Fiona Clare Cicconi',\n",
              "   'age': 57,\n",
              "   'title': 'Chief People Officer',\n",
              "   'yearBorn': 1966,\n",
              "   'fiscalYear': 2022,\n",
              "   'exercisedValue': 0,\n",
              "   'unexercisedValue': 0}],\n",
              " 'auditRisk': 10,\n",
              " 'boardRisk': 7,\n",
              " 'compensationRisk': 10,\n",
              " 'shareHolderRightsRisk': 10,\n",
              " 'overallRisk': 10,\n",
              " 'governanceEpochDate': 1709251200,\n",
              " 'compensationAsOfEpochDate': 1672444800,\n",
              " 'maxAge': 86400,\n",
              " 'priceHint': 2,\n",
              " 'previousClose': 148.74,\n",
              " 'open': 150.19,\n",
              " 'dayLow': 150.09,\n",
              " 'dayHigh': 152.55,\n",
              " 'regularMarketPreviousClose': 148.74,\n",
              " 'regularMarketOpen': 150.19,\n",
              " 'regularMarketDayLow': 150.09,\n",
              " 'regularMarketDayHigh': 152.55,\n",
              " 'beta': 1.044,\n",
              " 'trailingPE': 26.167242,\n",
              " 'forwardPE': 19.407928,\n",
              " 'volume': 19207179,\n",
              " 'regularMarketVolume': 19207179,\n",
              " 'averageVolume': 22858762,\n",
              " 'averageVolume10days': 26056220,\n",
              " 'averageDailyVolume10Day': 26056220,\n",
              " 'bid': 151.78,\n",
              " 'ask': 151.82,\n",
              " 'bidSize': 100,\n",
              " 'askSize': 100,\n",
              " 'marketCap': 1880263360512,\n",
              " 'fiftyTwoWeekLow': 100.28,\n",
              " 'fiftyTwoWeekHigh': 155.2,\n",
              " 'priceToSalesTrailing12Months': 6.1167865,\n",
              " 'fiftyDayAverage': 144.3128,\n",
              " 'twoHundredDayAverage': 135.1057,\n",
              " 'currency': 'USD',\n",
              " 'enterpriseValue': 1805907394560,\n",
              " 'profitMargins': 0.24007,\n",
              " 'floatShares': 11098690440,\n",
              " 'sharesOutstanding': 5671000064,\n",
              " 'sharesShort': 34869255,\n",
              " 'sharesShortPriorMonth': 37123330,\n",
              " 'sharesShortPreviousMonthDate': 1706659200,\n",
              " 'dateShortInterest': 1709164800,\n",
              " 'sharesPercentSharesOut': 0.0025,\n",
              " 'heldPercentInsiders': 0.00017000001,\n",
              " 'heldPercentInstitutions': 0.62116003,\n",
              " 'shortRatio': 1.24,\n",
              " 'impliedSharesOutstanding': 12444300288,\n",
              " 'bookValue': 22.743,\n",
              " 'priceToBook': 6.673262,\n",
              " 'lastFiscalYearEnd': 1703980800,\n",
              " 'nextFiscalYearEnd': 1735603200,\n",
              " 'mostRecentQuarter': 1703980800,\n",
              " 'earningsQuarterlyGrowth': 0.518,\n",
              " 'netIncomeToCommon': 73795002368,\n",
              " 'trailingEps': 5.8,\n",
              " 'forwardEps': 7.82,\n",
              " 'pegRatio': 1.14,\n",
              " 'lastSplitFactor': '20:1',\n",
              " 'lastSplitDate': 1658102400,\n",
              " 'enterpriseToRevenue': 5.875,\n",
              " 'enterpriseToEbitda': 18.028,\n",
              " '52WeekChange': 0.4726373,\n",
              " 'SandP52WeekChange': 0.31593728,\n",
              " 'exchange': 'NMS',\n",
              " 'quoteType': 'EQUITY',\n",
              " 'symbol': 'GOOG',\n",
              " 'underlyingSymbol': 'GOOG',\n",
              " 'shortName': 'Alphabet Inc.',\n",
              " 'longName': 'Alphabet Inc.',\n",
              " 'firstTradeDateEpochUtc': 1092922200,\n",
              " 'timeZoneFullName': 'America/New_York',\n",
              " 'timeZoneShortName': 'EDT',\n",
              " 'uuid': 'ee8cce8c-2475-31c0-8436-ecdf889cbfbd',\n",
              " 'messageBoardId': 'finmb_29096',\n",
              " 'gmtOffSetMilliseconds': -14400000,\n",
              " 'currentPrice': 151.77,\n",
              " 'targetHighPrice': 172.2,\n",
              " 'targetLowPrice': 145.0,\n",
              " 'targetMeanPrice': 162.2,\n",
              " 'targetMedianPrice': 165.0,\n",
              " 'recommendationMean': 1.8,\n",
              " 'recommendationKey': 'buy',\n",
              " 'numberOfAnalystOpinions': 11,\n",
              " 'totalCash': 110916001792,\n",
              " 'totalCashPerShare': 8.921,\n",
              " 'ebitda': 100171997184,\n",
              " 'totalDebt': 29866999808,\n",
              " 'quickRatio': 1.942,\n",
              " 'currentRatio': 2.097,\n",
              " 'totalRevenue': 307393986560,\n",
              " 'debtToEquity': 10.54,\n",
              " 'revenuePerShare': 24.338,\n",
              " 'returnOnAssets': 0.14366001,\n",
              " 'returnOnEquity': 0.27356002,\n",
              " 'freeCashflow': 58657751040,\n",
              " 'operatingCashflow': 101745999872,\n",
              " 'earningsGrowth': 0.56,\n",
              " 'revenueGrowth': 0.135,\n",
              " 'grossMargins': 0.56937003,\n",
              " 'ebitdaMargins': 0.32587,\n",
              " 'operatingMargins': 0.28849,\n",
              " 'financialCurrency': 'USD',\n",
              " 'trailingPegRatio': 1.5871}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(GOOG.history(period=\"10y\"))\n",
        "df2 = pd.DataFrame(msft.history(period=\"10y\"))\n",
        "AMZN = yf.Ticker(\"AMZN\")\n",
        "df3 = pd.DataFrame(AMZN.history(period=\"10y\"))\n",
        "META = yf.Ticker(\"META\")\n",
        "df4 = pd.DataFrame(META.history(period=\"10y\"))\n",
        "AAPL = yf.Ticker(\"AAPL\")\n",
        "df5 = pd.DataFrame(AAPL.history(period=\"10y\"))"
      ],
      "metadata": {
        "id": "0rqgsYzRvwGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From looking at the data I will:\n",
        "* Drop the date column since it does not contribute to the closing price\n",
        "* Drop the **dividends** and **Stock Splits** columns since there values are 0.\n",
        "* Make the **Open**, **High**, **Low** and **Volume** columns the features, since they can have an effect on the **Closing price**.\n",
        "* Make the **Close** column my label, since thats what I want the model to predict"
      ],
      "metadata": {
        "id": "CE28LKKXxBEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combines all of the financial data in the last 10 years of these stocks into one mega dataset\n",
        "combined_df = pd.concat([df1, df2, df3, df4, df5])\n",
        "#Counts the number of N/A values within the dataset\n",
        "na_count = combined_df.isna().sum()\n",
        "print(f\"The number of N/A values are: {na_count} \\n\")\n",
        "null_count = combined_df.isnull().sum()\n",
        "print(f\"The number of N/A values are: {null_count} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYwcVB7VxwkB",
        "outputId": "fab1d01d-655d-4fba-eff8-8441f00181c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of N/A values are: Open            0\n",
            "High            0\n",
            "Low             0\n",
            "Close           0\n",
            "Volume          0\n",
            "Dividends       0\n",
            "Stock Splits    0\n",
            "dtype: int64 \n",
            "\n",
            "The number of N/A values are: Open            0\n",
            "High            0\n",
            "Low             0\n",
            "Close           0\n",
            "Volume          0\n",
            "Dividends       0\n",
            "Stock Splits    0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect there seems to be no **missing values** and no **N/A values**."
      ],
      "metadata": {
        "id": "YUX637PtMBPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates the features\n",
        "features = combined_df.drop(columns = [\"Close\", \"Dividends\", \"Stock Splits\"])\n",
        "features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "uHK6J11gLwaJ",
        "outputId": "86775ba9-187b-4a6a-e61b-c38cccfbb47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Open       High        Low     Volume\n",
              "Date                                                                 \n",
              "2014-03-24 00:00:00-04:00  29.494200  29.511883  28.541767  121939352\n",
              "2014-03-25 00:00:00-04:00  29.041147  29.136787  28.567921   96769361\n",
              "2014-03-26 00:00:00-04:00  28.941769  29.179876  28.181868  103586819\n",
              "2014-03-27 00:00:00-04:00  28.322241  28.322241  27.570307     262719\n",
              "2014-03-28 00:00:00-04:00  27.983171  28.243956  27.857019     824257"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a372d61e-ee93-4add-bf2e-b3c8a3a1c4b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-03-24 00:00:00-04:00</th>\n",
              "      <td>29.494200</td>\n",
              "      <td>29.511883</td>\n",
              "      <td>28.541767</td>\n",
              "      <td>121939352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-25 00:00:00-04:00</th>\n",
              "      <td>29.041147</td>\n",
              "      <td>29.136787</td>\n",
              "      <td>28.567921</td>\n",
              "      <td>96769361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-26 00:00:00-04:00</th>\n",
              "      <td>28.941769</td>\n",
              "      <td>29.179876</td>\n",
              "      <td>28.181868</td>\n",
              "      <td>103586819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-27 00:00:00-04:00</th>\n",
              "      <td>28.322241</td>\n",
              "      <td>28.322241</td>\n",
              "      <td>27.570307</td>\n",
              "      <td>262719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-28 00:00:00-04:00</th>\n",
              "      <td>27.983171</td>\n",
              "      <td>28.243956</td>\n",
              "      <td>27.857019</td>\n",
              "      <td>824257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a372d61e-ee93-4add-bf2e-b3c8a3a1c4b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a372d61e-ee93-4add-bf2e-b3c8a3a1c4b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a372d61e-ee93-4add-bf2e-b3c8a3a1c4b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-178d7474-54b1-4c59-85c1-ebeddc333d05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-178d7474-54b1-4c59-85c1-ebeddc333d05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-178d7474-54b1-4c59-85c1-ebeddc333d05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "features",
              "summary": "{\n  \"name\": \"features\",\n  \"rows\": 12590,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-03-24 00:00:00-04:00\",\n        \"max\": \"2024-03-22 00:00:00-04:00\",\n        \"num_unique_values\": 2518,\n        \"samples\": [\n          \"2022-12-09 00:00:00-05:00\",\n          \"2015-11-05 00:00:00-05:00\",\n          \"2019-09-27 00:00:00-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.49592537878411,\n        \"min\": 14.220000267028809,\n        \"max\": 514.7100219726562,\n        \"num_unique_values\": 12359,\n        \"samples\": [\n          49.86374558506695,\n          168.30143170315836,\n          164.6253314788325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87.51136476268078,\n        \"min\": 14.520999908447266,\n        \"max\": 523.5700073242188,\n        \"num_unique_values\": 12429,\n        \"samples\": [\n          177.05053088327483,\n          150.95982340547195,\n          43.964048659742126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.51047599487582,\n        \"min\": 14.199999809265137,\n        \"max\": 506.010009765625,\n        \"num_unique_values\": 12427,\n        \"samples\": [\n          176.85105451107555,\n          140.16128022793035,\n          41.40087271379914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57690437,\n        \"min\": 158434,\n        \"max\": 759911600,\n        \"num_unique_values\": 12351,\n        \"samples\": [\n          13769700,\n          35389800,\n          30333700\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features[\"Open\"].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "13lKB73ezPpi",
        "outputId": "acf48f45-7cea-4390-cff4-57ddcbec9508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Date'>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = combined_df[\"Close\"]\n",
        "labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JB-vh2Qz8te",
        "outputId": "ea79431d-1198-4047-e5a4-885230ef293e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2014-03-24 00:00:00-04:00    28.840151\n",
              "2014-03-25 00:00:00-04:00    28.859825\n",
              "2014-03-26 00:00:00-04:00    28.193575\n",
              "2014-03-27 00:00:00-04:00    27.846546\n",
              "2014-03-28 00:00:00-04:00    27.922838\n",
              "Name: Close, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.head(), labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj6dlert0NKz",
        "outputId": "c445bd27-2bc0-4e90-ba3e-d54438198081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                Open       High        Low     Volume\n",
              " Date                                                                 \n",
              " 2014-03-24 00:00:00-04:00  29.494200  29.511883  28.541767  121939352\n",
              " 2014-03-25 00:00:00-04:00  29.041147  29.136787  28.567921   96769361\n",
              " 2014-03-26 00:00:00-04:00  28.941769  29.179876  28.181868  103586819\n",
              " 2014-03-27 00:00:00-04:00  28.322241  28.322241  27.570307     262719\n",
              " 2014-03-28 00:00:00-04:00  27.983171  28.243956  27.857019     824257,\n",
              " Date\n",
              " 2014-03-24 00:00:00-04:00    28.840151\n",
              " 2014-03-25 00:00:00-04:00    28.859825\n",
              " 2014-03-26 00:00:00-04:00    28.193575\n",
              " 2014-03-27 00:00:00-04:00    27.846546\n",
              " 2014-03-28 00:00:00-04:00    27.922838\n",
              " Name: Close, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 4932 features and labels respectively."
      ],
      "metadata": {
        "id": "ntmP0HOX0Xdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(features), len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY_yMCL70Q7N",
        "outputId": "34739906-c5d7-49a7-f6b9-14e56674b96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12590, 12590)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I've properly split the dataset into features and labels its time to preprocess it for the neural network.\n",
        "* **Normalization** - I will normalize the data to keep it's values within the range of 0-1 via the **MinMaxScaler**. This will allow me to do so, while keeping the original distributions.\n",
        "* **Encoders** - Since there is no non numerical data, there will be no need for me to use an encoder\n",
        "* **Training** and **Testing datasets** - In order to get a proper evaluation of the models performance and make sure that it generalizes well to new data, I will create a train dataset for training the model and a test dataset for testing the models predictions. The split will be **80%** for training and **20%** for testing."
      ],
      "metadata": {
        "id": "3bvlujzs2Ioc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Training and Testing datasets\n",
        "Will use **train_test_split** to split the dataset into a training set and test set"
      ],
      "metadata": {
        "id": "WkBuWsRhBFyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
        "len(X_train), len(y_train), X_train, y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_WJ7Xm2BO1M",
        "outputId": "f949a483-4ece-40f7-b421-f2d9f3cda0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10072,\n",
              " 10072,\n",
              "                                  Open        High         Low     Volume\n",
              " Date                                                                    \n",
              " 2018-03-14 00:00:00-04:00   89.041067   89.312535   87.524596   32132000\n",
              " 2018-01-02 00:00:00-05:00   80.248634   80.416343   79.661656   22483800\n",
              " 2014-08-15 00:00:00-04:00   38.016886   38.289775   37.863385   41611300\n",
              " 2016-09-07 00:00:00-04:00   24.927999   25.142996   24.752303  169457200\n",
              " 2018-03-16 00:00:00-04:00   42.351646   42.463066   42.107469  157618800\n",
              " ...                               ...         ...         ...        ...\n",
              " 2021-09-27 00:00:00-04:00  143.434056  143.917203  141.807154   74150700\n",
              " 2014-10-31 00:00:00-04:00   15.257500   15.286000   15.075000   91014000\n",
              " 2015-08-18 00:00:00-04:00   26.752001   26.974501   26.650000   41426000\n",
              " 2017-08-21 00:00:00-04:00   45.500000   45.650002   45.169998   18868000\n",
              " 2023-02-06 00:00:00-05:00  102.930000  103.949997  100.650002   81945200\n",
              " \n",
              " [10072 rows x 4 columns],\n",
              " Date\n",
              " 2018-03-14 00:00:00-04:00     87.852226\n",
              " 2018-01-02 00:00:00-05:00     80.080925\n",
              " 2014-08-15 00:00:00-04:00     38.195969\n",
              " 2016-09-07 00:00:00-04:00     25.050524\n",
              " 2018-03-16 00:00:00-04:00     42.202297\n",
              "                                 ...    \n",
              " 2021-09-27 00:00:00-04:00    143.335449\n",
              " 2014-10-31 00:00:00-04:00     15.273000\n",
              " 2015-08-18 00:00:00-04:00     26.750999\n",
              " 2017-08-21 00:00:00-04:00     45.333000\n",
              " 2023-02-06 00:00:00-05:00    102.180000\n",
              " Name: Close, Length: 10072, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Sequences from the DataFrame\n",
        "The current **dataframe** is a **time series dataframe** due to it having a **timestamp** per row alongside every **feature** of the row. In order to feed the data the the **LSTM** model, I will need to create **sequences** out of the dataframe so that the model can accept it."
      ],
      "metadata": {
        "id": "Uin8V1L1-9Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "X_train_scaled, X_test_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Rw_Xro_kdO",
        "outputId": "8aec6cc8-8721-48a9-c912-9e1cdc3113b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.14949562, 0.14692404, 0.1490913 , 0.04208415],\n",
              "        [0.13192797, 0.12944794, 0.13310355, 0.02938503],\n",
              "        [0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "        ...,\n",
              "        [0.02503946, 0.02446425, 0.02531465, 0.05431707],\n",
              "        [0.06249875, 0.06115129, 0.06297147, 0.02462585],\n",
              "        [0.17724629, 0.17567856, 0.17577926, 0.10764913]]),\n",
              " array([[0.31713612, 0.31892341, 0.322413  , 0.01332958],\n",
              "        [0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "        [0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "        ...,\n",
              "        [0.32643548, 0.32954495, 0.33262552, 0.01542647],\n",
              "        [0.54560155, 0.54932543, 0.54474621, 0.01607683],\n",
              "        [0.47629942, 0.477558  , 0.47800911, 0.03825098]]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to structure your data into sequences so that the LSTM can process. Each sequence contains **n** consecutive data points, where **n** is the number of timesteps. Since the **sequnces** are being made after the **MinMaxScaler**, I am now working with a **Numpy Array**."
      ],
      "metadata": {
        "id": "NHtTIdu7ATYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(X, y, n_steps): #n_steps is the sequence length that i want to cfreate\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - n_steps): #Iterates over the dataset\n",
        "        Xs.append(X[i:(i + n_steps)])\n",
        "        ys.append(y[i + n_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "n_steps = 5  # Number of timesteps in each sequence\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, n_steps)\n",
        "\n",
        "X_train_seq, y_train_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLSnB6xgA4L2",
        "outputId": "1865bf07-2379-414d-dc36-18a9159806aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.14949562, 0.14692404, 0.1490913 , 0.04208415],\n",
              "         [0.13192797, 0.12944794, 0.13310355, 0.02938503],\n",
              "         [0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ]],\n",
              " \n",
              "        [[0.13192797, 0.12944794, 0.13310355, 0.02938503],\n",
              "         [0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ],\n",
              "         [0.59182987, 0.58546652, 0.59918298, 0.03179528]],\n",
              " \n",
              "        [[0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ],\n",
              "         [0.59182987, 0.58546652, 0.59918298, 0.03179528],\n",
              "         [0.02730098, 0.02647889, 0.02768647, 0.12463728]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.13003257, 0.12750933, 0.13041214, 0.14872142],\n",
              "         [0.04913684, 0.04808771, 0.04946016, 0.08668811],\n",
              "         [0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564]],\n",
              " \n",
              "        [[0.04913684, 0.04808771, 0.04946016, 0.08668811],\n",
              "         [0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707]],\n",
              " \n",
              "        [[0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707],\n",
              "         [0.06249875, 0.06115129, 0.06297147, 0.02462585]]]),\n",
              " array([312.12472534,  27.88154602, 318.12481689, ...,  26.75099945,\n",
              "         45.33300018, 102.18000031]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the test set sequences\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, n_steps)\n",
        "X_test_seq, y_test_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtVxHNSTAaFc",
        "outputId": "00c94228-488f-42ef-d3a6-bca80157ef7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.31713612, 0.31892341, 0.322413  , 0.01332958],\n",
              "         [0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466]],\n",
              " \n",
              "        [[0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466],\n",
              "         [0.34638226, 0.34753888, 0.34952957, 0.08172671]],\n",
              " \n",
              "        [[0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466],\n",
              "         [0.34638226, 0.34753888, 0.34952957, 0.08172671],\n",
              "         [0.21322113, 0.21614918, 0.21682986, 0.02681422]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.02189456, 0.02173646, 0.02268381, 0.11549662],\n",
              "         [0.4803394 , 0.48616052, 0.48895738, 0.03169987],\n",
              "         [0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285]],\n",
              " \n",
              "        [[0.4803394 , 0.48616052, 0.48895738, 0.03169987],\n",
              "         [0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647]],\n",
              " \n",
              "        [[0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647],\n",
              "         [0.54560155, 0.54932543, 0.54474621, 0.01607683]]]),\n",
              " array([180.94909668, 119.06749725, 122.94000244, ..., 173.18624878,\n",
              "        275.2979126 , 240.82440186]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This create sequences function will make sure that y is the same length as x while not making y a sequence."
      ],
      "metadata": {
        "id": "Hja-INMXgYLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(X, y, n_steps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - n_steps):\n",
        "        Xs.append(X[i:i + n_steps, :])  # Assuming X is a 2D NumPy array\n",
        "        ys.append(y[i + n_steps])       # Assuming y is a 1D NumPy array\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "n_steps = 5  # Number of timesteps in each sequence\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, n_steps)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, n_steps)\n",
        "X_train_seq, y_train_seq, X_test_seq, y_test_seq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgNK3z1ggW4K",
        "outputId": "dfb03d16-ef14-4276-e0bb-466ca66cfa13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.14949562, 0.14692404, 0.1490913 , 0.04208415],\n",
              "         [0.13192797, 0.12944794, 0.13310355, 0.02938503],\n",
              "         [0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ]],\n",
              " \n",
              "        [[0.13192797, 0.12944794, 0.13310355, 0.02938503],\n",
              "         [0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ],\n",
              "         [0.59182987, 0.58546652, 0.59918298, 0.03179528]],\n",
              " \n",
              "        [[0.04754717, 0.04669251, 0.04811489, 0.05456097],\n",
              "         [0.02139503, 0.02086635, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ],\n",
              "         [0.59182987, 0.58546652, 0.59918298, 0.03179528],\n",
              "         [0.02730098, 0.02647889, 0.02768647, 0.12463728]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.13003257, 0.12750933, 0.13041214, 0.14872142],\n",
              "         [0.04913684, 0.04808771, 0.04946016, 0.08668811],\n",
              "         [0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564]],\n",
              " \n",
              "        [[0.04913684, 0.04808771, 0.04946016, 0.08668811],\n",
              "         [0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707]],\n",
              " \n",
              "        [[0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817509, 0.25419204, 0.25946433, 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707],\n",
              "         [0.06249875, 0.06115129, 0.06297147, 0.02462585]]]),\n",
              " array([312.12472534,  27.88154602, 318.12481689, ...,  26.75099945,\n",
              "         45.33300018, 102.18000031]),\n",
              " array([[[0.31713612, 0.31892341, 0.322413  , 0.01332958],\n",
              "         [0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466]],\n",
              " \n",
              "        [[0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466],\n",
              "         [0.34638226, 0.34753888, 0.34952957, 0.08172671]],\n",
              " \n",
              "        [[0.06638344, 0.06677994, 0.06782584, 0.0229985 ],\n",
              "         [0.09878976, 0.09900326, 0.10075195, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466],\n",
              "         [0.34638226, 0.34753888, 0.34952957, 0.08172671],\n",
              "         [0.21322113, 0.21614918, 0.21682986, 0.02681422]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.02189456, 0.02173646, 0.02268381, 0.11549662],\n",
              "         [0.4803394 , 0.48616052, 0.48895738, 0.03169987],\n",
              "         [0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285]],\n",
              " \n",
              "        [[0.4803394 , 0.48616052, 0.48895738, 0.03169987],\n",
              "         [0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647]],\n",
              " \n",
              "        [[0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676564, 0.01463909, 1.        ],\n",
              "         [0.33458279, 0.3371478 , 0.32910401, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647],\n",
              "         [0.54560155, 0.54932543, 0.54474621, 0.01607683]]]),\n",
              " array([180.94909668, 119.06749725, 122.94000244, ..., 173.18624878,\n",
              "        275.2979126 , 240.82440186]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_seq), len(y_train_seq), len(X_test_seq), len(y_test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0E_QccHg21o",
        "outputId": "c1137010-9fce-4ddd-a23a-a7b6405eab26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10067, 10067, 2513, 2513)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the model\n",
        "Now its time to create the model. As mentioned earlier I will now use the **LSTM** layers. This is because **LSTM** are particularly well-suited for making predictions based on time series data, like stock prices, because they can capture temporal dependencies and patterns over different time intervals.\n",
        "\n",
        "* **Memory Cell:** Each **LSTM unit** has a memory cell that can maintain information in memory for long periods. This is crucial for understanding context in time series data.\n",
        "\n",
        "* **Gates:** LSTMs have three types of gates that regulate the flow of information: the **input gate**, which controls the extent to which a new value flows into the memory cell; the **forget gate**, which controls the extent to which a value remains in the memory cell; and the **output gate**, which controls the extent to which the value in the memory cell is used to compute the output activation of the block.\n",
        "\n",
        "* **Handling Long-Term Dependencies:** Traditional RNNs often face issues with **vanishing** or **exploding gradients**, making it hard to learn long-term dependencies. **LSTMs** address this problem, making them effective for tasks where understanding long-term dependencies is crucial."
      ],
      "metadata": {
        "id": "LV60va8rchq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eluQJxRPhOvA",
        "outputId": "76b1f786-1df2-4227-b55a-6033bdb5ae93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10067, 5, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.losses import MSE, MAE\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "def create_model1():\n",
        "  model_1 = tf.keras.models.Sequential([\n",
        "     LSTM(50, return_sequences = True), #By default, the LSTM layer has the tanh activation function\n",
        "     LSTM(10),\n",
        "     Dense(1, activation = \"linear\") #Will return one values, which is the closing price. The linear actiation function just returns the value\n",
        "\n",
        "  ])\n",
        "\n",
        "  model_1.compile( loss = MAE,\n",
        "                optimizer = Adam(),\n",
        "                 metrics = [\"MAE\"])\n",
        "  return model_1"
      ],
      "metadata": {
        "id": "lacjUbd-gqkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = create_model1()\n",
        "\n",
        "history_1 = model_1.fit(X_train_seq, y_train_seq, epochs = 10, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9tYLWkvQn9P",
        "outputId": "70fc3b9b-c3f8-46b8-99f4-aa5cffa324d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10067/10067 [==============================] - 58s 5ms/step - loss: 81.6822 - MAE: 81.6822 - val_loss: 69.2370 - val_MAE: 69.2370\n",
            "Epoch 2/10\n",
            "10067/10067 [==============================] - 57s 6ms/step - loss: 68.4836 - MAE: 68.4836 - val_loss: 66.2320 - val_MAE: 66.2320\n",
            "Epoch 3/10\n",
            "10067/10067 [==============================] - 52s 5ms/step - loss: 66.9688 - MAE: 66.9688 - val_loss: 65.7479 - val_MAE: 65.7479\n",
            "Epoch 4/10\n",
            "10067/10067 [==============================] - 52s 5ms/step - loss: 66.7498 - MAE: 66.7498 - val_loss: 65.7033 - val_MAE: 65.7033\n",
            "Epoch 5/10\n",
            "10067/10067 [==============================] - 57s 6ms/step - loss: 66.7197 - MAE: 66.7197 - val_loss: 65.7057 - val_MAE: 65.7057\n",
            "Epoch 6/10\n",
            "10067/10067 [==============================] - 53s 5ms/step - loss: 66.7163 - MAE: 66.7163 - val_loss: 65.7103 - val_MAE: 65.7103\n",
            "Epoch 7/10\n",
            "10067/10067 [==============================] - 58s 6ms/step - loss: 66.7166 - MAE: 66.7166 - val_loss: 65.7103 - val_MAE: 65.7103\n",
            "Epoch 8/10\n",
            "10067/10067 [==============================] - 57s 6ms/step - loss: 66.7167 - MAE: 66.7167 - val_loss: 65.7104 - val_MAE: 65.7104\n",
            "Epoch 9/10\n",
            "10067/10067 [==============================] - 57s 6ms/step - loss: 66.7171 - MAE: 66.7171 - val_loss: 65.7084 - val_MAE: 65.7084\n",
            "Epoch 10/10\n",
            "10067/10067 [==============================] - 56s 6ms/step - loss: 66.7173 - MAE: 66.7173 - val_loss: 65.7086 - val_MAE: 65.7086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base model results\n",
        "Since this was the first model I will treat it as the base. Now, when it comes to the actual results a validation loss of 65% is not good. That means that the model has an accuracy of 35%, but thats ok. Now that I have a benchmark, I can now start optimizing the models **hyperparameters** and messing around with its architecture. Not only that, but because the dataset is from the stock market, I can also increase the dataset if I feel like its a neccessity. But for now, I'll stick to the model.\n",
        "\n",
        "# Changes that I'll will make\n",
        "* **Increase the layers and number of neurons in the model** - The model may be to simple to detect any meaningful patterns within the data, causing it to **underfit**. I will increase the models complexity to see if theres an improvement to performance.\n",
        "* **Create a EarlyStopping callback to stop the training process before overfitting** - I will implement a **EarlyStopping callback** to make sure to avoid **overfitting** while I mess around with other **hyperparameters**.\n",
        "* **Create a LearningRateScheduler for exponential learning rate decay** - I plan on messing around with the learning rate(most likely increasing it) so I want to implement **Exponential Learning Rate Deacay** after certain epochs to increase/optimize model's performance and avoid **overfitting**.\n",
        "* **Add more data** - If all of these experiments do not yeild notable results, I will increase the dataset and see of the performances improve.\n",
        "* **Create functions to get a deeper evaluation of models performance** - I will create functions to test and evaluate the model's predictions such as a function that plots the **loss curves** and a function that calculates the **Mean Square Error(MSE)**, **Root Mean Square Error(RMSE)**, **Mean Absolute Error(MAE)**, **R-Squared(R2)**, and the **Explained Variance(EV)**."
      ],
      "metadata": {
        "id": "lG6Ei_KIUWL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions\n",
        "I Will create helper functions that will allow me to streamline the process of analyzing a models performance.\n"
      ],
      "metadata": {
        "id": "ojI4cIVRa_kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
        "\n",
        "def deep_analysis_reg(model, X_test, y_test):\n",
        "  \"\"\"\n",
        "  This function will take in a model, the test set along with the proper predictions and evaluate the models performance.\n",
        "  \"\"\"\n",
        "  #Will store the models predictions to use for perfomance anlysis\n",
        "  preds = model.predict(X_test)\n",
        "\n",
        "  #Lower values for the error metrics indicates better performance\n",
        "  mse = mean_squared_error(y_test, preds)\n",
        "  rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "  mae = mean_absolute_error(y_test, preds)\n",
        "  #Higher values for r2 and explained variance indicates good performance\n",
        "  r2 = r2_score(y_test, preds)\n",
        "  evs = explained_variance_score(y_test, preds)\n",
        "\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"Root Mean Squared Error: {rmse}\")\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"R-Squared: {r2}\")\n",
        "  print(f\"Explained Variance Score: {evs}\")\n",
        "\n",
        "  obj = {\n",
        "      \"MSE\":mse,\n",
        "      \"RMSE\":rmse,\n",
        "      \"MAE\":mae,\n",
        "      \"R2\":r2,\n",
        "      \"EVS\":evs\n",
        "  }\n",
        "  #Returns all the metrics in an object when done\n",
        "  return obj\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "58fwQ__WbI9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2\n",
        "For the second experiment, I will increase the model's complexity but leave everything else the same."
      ],
      "metadata": {
        "id": "p7FiDwDMZWTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = tf.keras.models.Sequential([\n",
        "    LSTM(100, return_sequences = True),  #Will set return_sequences to all layers but last LSTM layer\n",
        "    LSTM(100, return_sequences = True),\n",
        "    LSTM(100),\n",
        "    Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_2.compile(loss = MAE,\n",
        "                optimizer = Adam(),\n",
        "                metrics = [\"MAE\"])"
      ],
      "metadata": {
        "id": "TMqICHMzYKqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model_2.fit(X_train_seq, y_train_seq, epochs = 10, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dLednu3ZP1p",
        "outputId": "1ef94cf6-1d14-41f8-a25d-8dfee435e788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10067/10067 [==============================] - 106s 7ms/step - loss: 68.2163 - MAE: 68.2163 - val_loss: 65.7367 - val_MAE: 65.7367\n",
            "Epoch 2/10\n",
            "10067/10067 [==============================] - 66s 7ms/step - loss: 66.7462 - MAE: 66.7462 - val_loss: 65.7063 - val_MAE: 65.7063\n",
            "Epoch 3/10\n",
            "10067/10067 [==============================] - 72s 7ms/step - loss: 66.7536 - MAE: 66.7536 - val_loss: 65.7023 - val_MAE: 65.7023\n",
            "Epoch 4/10\n",
            "10067/10067 [==============================] - 87s 9ms/step - loss: 66.7495 - MAE: 66.7495 - val_loss: 65.7037 - val_MAE: 65.7037\n",
            "Epoch 5/10\n",
            "10067/10067 [==============================] - 89s 9ms/step - loss: 66.7429 - MAE: 66.7429 - val_loss: 65.7055 - val_MAE: 65.7055\n",
            "Epoch 6/10\n",
            "10067/10067 [==============================] - 85s 8ms/step - loss: 66.7411 - MAE: 66.7411 - val_loss: 65.7029 - val_MAE: 65.7029\n",
            "Epoch 7/10\n",
            "10067/10067 [==============================] - 77s 8ms/step - loss: 66.7464 - MAE: 66.7464 - val_loss: 65.7552 - val_MAE: 65.7552\n",
            "Epoch 8/10\n",
            "10067/10067 [==============================] - 85s 8ms/step - loss: 66.7350 - MAE: 66.7350 - val_loss: 65.7198 - val_MAE: 65.7198\n",
            "Epoch 9/10\n",
            "10067/10067 [==============================] - 92s 9ms/step - loss: 66.7480 - MAE: 66.7480 - val_loss: 65.7237 - val_MAE: 65.7237\n",
            "Epoch 10/10\n",
            "10067/10067 [==============================] - 74s 7ms/step - loss: 66.7542 - MAE: 66.7542 - val_loss: 65.7208 - val_MAE: 65.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_2 = deep_analysis_reg(model = model_2, X_test = X_test_seq, y_test = y_test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWD7YXVBeLF9",
        "outputId": "8a9226db-5426-4e5e-e396-297d87639d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error: 7574.579209293798\n",
            "Root Mean Squared Error: 87.03205851462896\n",
            "Mean Absolute Error: 65.72078345450944\n",
            "R-Squared: -0.04618906745832407\n",
            "Explained Variance Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of experiment 2\n",
        "So, the permance is still bad, but one thing that i noticed was the this is a **many-to-one** problem not a **many-to-many** problem. That means that I should not be turning y-test into a sequence, since the model is trying to predict one value per sequence. Will see if theres an improvement in results after I make the adjustment. Will keep the smae architecture to keep analysis same."
      ],
      "metadata": {
        "id": "ZjxkatWbe7c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "model_3 = tf.keras.models.Sequential([\n",
        "    LSTM(100, return_sequences = True),  #Will set return_sequences to all layers but last LSTM layer\n",
        "    LSTM(100, return_sequences = True),\n",
        "    LSTM(100),\n",
        "    Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_3.compile(loss = MAE,\n",
        "                optimizer = Adam(),\n",
        "                metrics = [\"MAE\"])\n",
        "\n",
        "history_3 = model_3.fit(X_train_seq, y_train_seq, epochs = 10, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEmYiSntfndD",
        "outputId": "96d90500-fdaa-4cab-e9ce-e81b29111766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10067/10067 [==============================] - 76s 7ms/step - loss: 68.2770 - MAE: 68.2770 - val_loss: 65.8055 - val_MAE: 65.8055\n",
            "Epoch 2/10\n",
            "10067/10067 [==============================] - 70s 7ms/step - loss: 66.7519 - MAE: 66.7519 - val_loss: 65.7048 - val_MAE: 65.7048\n",
            "Epoch 3/10\n",
            "10067/10067 [==============================] - 66s 7ms/step - loss: 66.7530 - MAE: 66.7530 - val_loss: 65.7525 - val_MAE: 65.7525\n",
            "Epoch 4/10\n",
            "10067/10067 [==============================] - 70s 7ms/step - loss: 66.7494 - MAE: 66.7494 - val_loss: 65.7180 - val_MAE: 65.7180\n",
            "Epoch 5/10\n",
            "10067/10067 [==============================] - 67s 7ms/step - loss: 66.7465 - MAE: 66.7465 - val_loss: 65.7028 - val_MAE: 65.7028\n",
            "Epoch 6/10\n",
            "10067/10067 [==============================] - 71s 7ms/step - loss: 66.7412 - MAE: 66.7412 - val_loss: 65.7773 - val_MAE: 65.7773\n",
            "Epoch 7/10\n",
            "10067/10067 [==============================] - 67s 7ms/step - loss: 66.7560 - MAE: 66.7560 - val_loss: 65.7448 - val_MAE: 65.7448\n",
            "Epoch 8/10\n",
            "10067/10067 [==============================] - 70s 7ms/step - loss: 66.7409 - MAE: 66.7409 - val_loss: 65.7997 - val_MAE: 65.7997\n",
            "Epoch 9/10\n",
            "10067/10067 [==============================] - 66s 7ms/step - loss: 66.7514 - MAE: 66.7514 - val_loss: 65.7169 - val_MAE: 65.7169\n",
            "Epoch 10/10\n",
            "10067/10067 [==============================] - 75s 7ms/step - loss: 66.7473 - MAE: 66.7473 - val_loss: 65.7144 - val_MAE: 65.7144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_analysis_reg(model = model_3, X_test = X_test_seq, y_test = y_test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzp2BhG7kZ3S",
        "outputId": "0bf7d9fa-0756-4a05-af17-0671dfd81f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 3ms/step\n",
            "Mean Squared Error: 7587.141807669812\n",
            "Root Mean Squared Error: 87.10420086120882\n",
            "Mean Absolute Error: 65.7143474090066\n",
            "R-Squared: -0.04792419395402825\n",
            "Explained Variance Score: 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MSE': 7587.141807669812,\n",
              " 'RMSE': 87.10420086120882,\n",
              " 'MAE': 65.7143474090066,\n",
              " 'R2': -0.04792419395402825,\n",
              " 'EVS': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of experiment 3\n",
        "Will change the temporal window of the sequence to 3 days to see if there a difference while changing the number of neurons to 50."
      ],
      "metadata": {
        "id": "GHrmgE-6kFS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 3  # Number of timesteps in each sequence\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train, n_steps)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test, n_steps)\n",
        "X_train_seq, y_train_seq, X_test_seq, y_test_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUMx-QB5knAA",
        "outputId": "09397a17-5aeb-4d90-bfb3-749852379e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.14949561, 0.14692402, 0.14909129, 0.04208415],\n",
              "         [0.13192793, 0.12944789, 0.1331035 , 0.02938503],\n",
              "         [0.04754717, 0.0466925 , 0.04811488, 0.05456097]],\n",
              " \n",
              "        [[0.13192793, 0.12944789, 0.1331035 , 0.02938503],\n",
              "         [0.04754717, 0.0466925 , 0.04811488, 0.05456097],\n",
              "         [0.02139504, 0.02086636, 0.02145606, 0.22283391]],\n",
              " \n",
              "        [[0.04754717, 0.0466925 , 0.04811488, 0.05456097],\n",
              "         [0.02139504, 0.02086636, 0.02145606, 0.22283391],\n",
              "         [0.0562082 , 0.05489072, 0.05674441, 0.207252  ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.04354082, 0.04368625, 0.04424274, 0.15095056],\n",
              "         [0.25817506, 0.25419201, 0.2594643 , 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564]],\n",
              " \n",
              "        [[0.25817506, 0.25419201, 0.2594643 , 0.09738988],\n",
              "         [0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707]],\n",
              " \n",
              "        [[0.00207297, 0.0015028 , 0.00177914, 0.11958564],\n",
              "         [0.02503946, 0.02446425, 0.02531465, 0.05431707],\n",
              "         [0.06249875, 0.06115129, 0.06297147, 0.02462585]]]),\n",
              " array([ 25.05052757,  42.20229721, 312.12472534, ...,  26.75099945,\n",
              "         45.33300018, 102.18000031]),\n",
              " array([[[0.31713612, 0.31892341, 0.322413  , 0.01332958],\n",
              "         [0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638345, 0.06677995, 0.06782585, 0.0229985 ]],\n",
              " \n",
              "        [[0.21596876, 0.21571503, 0.21070691, 0.20301583],\n",
              "         [0.06638345, 0.06677995, 0.06782585, 0.0229985 ],\n",
              "         [0.09878978, 0.09900328, 0.10075197, 0.10490386]],\n",
              " \n",
              "        [[0.06638345, 0.06677995, 0.06782585, 0.0229985 ],\n",
              "         [0.09878978, 0.09900328, 0.10075197, 0.10490386],\n",
              "         [0.38964608, 0.3996304 , 0.39598953, 0.03573466]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.32821983, 0.33116567, 0.33340586, 0.06772198],\n",
              "         [0.01525399, 0.01676565, 0.0146391 , 1.        ],\n",
              "         [0.33458289, 0.3371479 , 0.32910411, 0.05855285]],\n",
              " \n",
              "        [[0.01525399, 0.01676565, 0.0146391 , 1.        ],\n",
              "         [0.33458289, 0.3371479 , 0.32910411, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647]],\n",
              " \n",
              "        [[0.33458289, 0.3371479 , 0.32910411, 0.05855285],\n",
              "         [0.32643548, 0.32954495, 0.33262552, 0.01542647],\n",
              "         [0.54560155, 0.54932543, 0.54474621, 0.01607683]]]),\n",
              " array([ 62.35904312, 204.06349182, 180.94909668, ..., 173.18624878,\n",
              "        275.2979126 , 240.82441711]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "model_4 = tf.keras.models.Sequential([\n",
        "    LSTM(50, return_sequences = True),  #Will set return_sequences to all layers but last LSTM layer\n",
        "    LSTM(50, return_sequences = True),\n",
        "    LSTM(50),\n",
        "    Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_4.compile(loss = MAE,\n",
        "                optimizer = Adam(),\n",
        "                metrics = [\"MAE\"])\n",
        "\n",
        "history_4 = model_4.fit(X_train_seq, y_train_seq, epochs = 5, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgOh2wyFj1Rs",
        "outputId": "63bbb53f-0e2f-4aed-f7f8-0319c0478c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10069/10069 [==============================] - 103s 7ms/step - loss: 69.8609 - MAE: 69.8609 - val_loss: 65.7173 - val_MAE: 65.7173\n",
            "Epoch 2/5\n",
            "10069/10069 [==============================] - 66s 7ms/step - loss: 66.7309 - MAE: 66.7309 - val_loss: 65.7246 - val_MAE: 65.7246\n",
            "Epoch 3/5\n",
            "10069/10069 [==============================] - 66s 7ms/step - loss: 66.7321 - MAE: 66.7321 - val_loss: 65.7065 - val_MAE: 65.7065\n",
            "Epoch 4/5\n",
            "10069/10069 [==============================] - 65s 6ms/step - loss: 66.7294 - MAE: 66.7294 - val_loss: 65.7538 - val_MAE: 65.7538\n",
            "Epoch 5/5\n",
            "10069/10069 [==============================] - 66s 7ms/step - loss: 66.7344 - MAE: 66.7344 - val_loss: 65.7086 - val_MAE: 65.7086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deep_analysis_reg(model = model_4, X_test = X_test_seq, y_test = y_test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny81z8M6kZIG",
        "outputId": "56831bec-9d01-4880-fc44-f6a2b1ebf4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 3ms/step\n",
            "Mean Squared Error: 7614.8748064503425\n",
            "Root Mean Squared Error: 87.2632500337361\n",
            "Mean Absolute Error: 65.7085636138916\n",
            "R-Squared: -0.051968367234902724\n",
            "Explained Variance Score: 1.155448865364228e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MSE': 7614.8748064503425,\n",
              " 'RMSE': 87.2632500337361,\n",
              " 'MAE': 65.7085636138916,\n",
              " 'R2': -0.051968367234902724,\n",
              " 'EVS': 1.155448865364228e-06}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4\n",
        "Since there is still not any notable increase in performance I will increase the learning rate and see if that fixes the issue."
      ],
      "metadata": {
        "id": "ykDOaGznml56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "model_5 = tf.keras.models.Sequential([\n",
        "    LSTM(50, return_sequences = True),  #Will set return_sequences to all layers but last LSTM layer\n",
        "    LSTM(50, return_sequences = True),\n",
        "    LSTM(50),\n",
        "    Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_5.compile(loss = MAE,\n",
        "                optimizer = Adam(learning_rate = 0.1),\n",
        "                metrics = [\"MAE\"])\n",
        "\n",
        "history_5 = model_5.fit(X_train_seq, y_train_seq, epochs = 5, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvn8m-qZmexq",
        "outputId": "97ce55fc-bb76-4e8b-bf22-4c4e82c4621e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10069/10069 [==============================] - 79s 7ms/step - loss: 67.7213 - MAE: 67.7213 - val_loss: 66.5141 - val_MAE: 66.5141\n",
            "Epoch 2/5\n",
            "10069/10069 [==============================] - 69s 7ms/step - loss: 67.7849 - MAE: 67.7849 - val_loss: 66.0267 - val_MAE: 66.0267\n",
            "Epoch 3/5\n",
            "10069/10069 [==============================] - 64s 6ms/step - loss: 67.6238 - MAE: 67.6238 - val_loss: 66.2186 - val_MAE: 66.2186\n",
            "Epoch 4/5\n",
            "10069/10069 [==============================] - 69s 7ms/step - loss: 67.8401 - MAE: 67.8401 - val_loss: 66.1678 - val_MAE: 66.1678\n",
            "Epoch 5/5\n",
            "10069/10069 [==============================] - 66s 7ms/step - loss: 67.6290 - MAE: 67.6290 - val_loss: 65.8087 - val_MAE: 65.8087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 5 analysis\n",
        "Since the loss is not decreasing, I might be facing a **vanishing gradient** problem(the **gradient** becomes so small that the model can't properly learn the weights), so I will implement **gradient clipping** to try an handle this issue. On top of that i will implement **BatchNormalization**. **Batch normalization** standardizes the inputs to a layer for each mini-batch, stabilizing the learning process."
      ],
      "metadata": {
        "id": "vGLpaJLsoZim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model_6 = tf.keras.models.Sequential([\n",
        "    LSTM(50, return_sequences = True),  #Will set return_sequences to all layers but last LSTM layer\n",
        "    BatchNormalization(),\n",
        "    LSTM(50, return_sequences = True),\n",
        "    BatchNormalization(),\n",
        "    LSTM(50, activation =\"relu\"),\n",
        "    Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_6.compile(loss = MAE,\n",
        "                optimizer = Adam(learning_rate = 0.01, clipvalue=0.5),  # Clipvalue restricts gradients to [-1, 1]\n",
        "                metrics = [\"MAE\"])\n",
        "\n",
        "history_6 = model_6.fit(X_train_seq, y_train_seq, epochs = 5, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "asZ_983Hn4pW",
        "outputId": "ff8f3462-7283-4f49-b435-6fd095d1cb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10069/10069 [==============================] - 143s 14ms/step - loss: 69.0390 - MAE: 69.0390 - val_loss: 127.0108 - val_MAE: 127.0108\n",
            "Epoch 2/5\n",
            " 3560/10069 [=========>....................] - ETA: 1:19 - loss: 67.7009 - MAE: 67.7009"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a655e1403279>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 metrics = [\"MAE\"])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m history_6 = model_6.fit(X_train_seq, y_train_seq, epochs = 5, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n\u001b[0m\u001b[1;32m     18\u001b[0m validation_steps = len(X_test_seq)) \n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, LeakyReLU, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model_7 = tf.keras.models.Sequential([\n",
        "    LSTM(100, return_sequences=True, activation='tanh'),  # LSTM default activation is 'tanh'\n",
        "    LSTM(100, return_sequences=True),\n",
        "    LSTM(100, activation='relu'),  # Using ReLU in the last LSTM layer\n",
        "    Dropout(0.5),\n",
        "    Dense(1)  # Using LeakyReLU in the Dense layer\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Define an optimizer with gradient clipping\n",
        "optimizer = Adam(learning_rate=0.001, clipvalue=1.0)  # Clipvalue restricts gradients to [-1, 1]\n",
        "\n",
        "# Compile the model with this optimizer\n",
        "model_7.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['MAE'])\n",
        "\n"
      ],
      "metadata": {
        "id": "Myk-MJ3vvk9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944e6013-17c4-4656-f14f-f7b225fc35ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_52 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_7 = model_7.fit(X_train_seq, y_train_seq, epochs = 5, steps_per_epoch = len(X_train_seq), validation_data = (X_test_seq, y_test_seq),\n",
        "validation_steps = len(X_test_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytU89TyTwA5P",
        "outputId": "9922cdf2-7365-4dad-9dc5-f95f4d378882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10067/10067 [==============================] - 115s 11ms/step - loss: 70.5568 - MAE: 70.5568 - val_loss: 65.7315 - val_MAE: 65.7315\n",
            "Epoch 2/5\n",
            "10067/10067 [==============================] - 106s 10ms/step - loss: 69.3293 - MAE: 69.3293 - val_loss: 66.4745 - val_MAE: 66.4745\n",
            "Epoch 3/5\n",
            "10067/10067 [==============================] - 111s 11ms/step - loss: 70.1035 - MAE: 70.1035 - val_loss: 67.1328 - val_MAE: 67.1328\n",
            "Epoch 4/5\n",
            "10067/10067 [==============================] - 107s 11ms/step - loss: 69.8265 - MAE: 69.8265 - val_loss: 65.7521 - val_MAE: 65.7521\n",
            "Epoch 5/5\n",
            "10067/10067 [==============================] - 108s 11ms/step - loss: 69.8083 - MAE: 69.8083 - val_loss: 65.6781 - val_MAE: 65.6781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Pipeline\n",
        "When it comes to keras/tensorflow models, the sklearn pipeline is not fully compatable with it due to it having a fit_transform feature that the models dont. To use a keras/tensorflow model with the sklearn pipeline I need to import the **`KerasClassifier`**. The **KerasClassifier** is a **sklearn wrapper** around the Keras model which allows it to be used like a standard **sklearn estimator**.  "
      ],
      "metadata": {
        "id": "x61rQHFplVBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Need to upgrade tensorflow since the keras classifier is a part of tensorflow 2.0\n",
        "!pip install keras==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VtVd6y1nkPh",
        "outputId": "3328ad63-20d7-4cac-cb0c-282b2f9a2d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "\n",
        "# Create a KerasClassifier, which is a scikit-learn wrapper for Keras models\n",
        "model = KerasRegressor(build_fn=create_model1, epochs=10, batch_size=10, verbose=0)\n",
        "#Create the pipeline with the lstm neural network\n",
        "pipeline = Pipeline([(\"Scaler\",MinMaxScaler()),\n",
        "                        (\"NeuralNetwork\", model)])\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "cki3PYlI2wU1",
        "outputId": "58ea1213-6a5a-485b-cb0d-11b7d141bd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1591f24ffb78>:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasRegressor(build_fn=create_model1, epochs=10, batch_size=10, verbose=0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"lstm_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n       inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n       training=True\n       mask=None\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1591f24ffb78>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"lstm_2\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n       inputs=tf.Tensor(shape=(None, 4), dtype=float32)\n       training=True\n       mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.predict(x_test)"
      ],
      "metadata": {
        "id": "4X8SZiEFm4gO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}