{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNK+ETubNxWbtkWZ6o+VdHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SteffanBurnette/TensorFlow-/blob/Testing_out_regression_neural_network_for_predicting_direction_of_future_stock_price/Stock_price_analysis_test_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Goal: Create a Regression neureal network that will be able to predict the future price of a stock when given the following metrics:\n",
        "* **Opening Price** - The price that the security started the day as.\n",
        "* **High** - The highest price of the security for the day.\n",
        "* **Low** - The lowest price of the security for the day.\n",
        "* **Closing price** - The price of the security when the market closes.\n",
        "* **Trading Volume** - The total quantity of shares or contracts traded for a specified security.\n",
        "\n",
        "When preparing the data, I think it would be best to **normalize** it since i still want to keep the proper distributions intact, but the put all values within the same range so that the model can make more precise decisions.\n",
        "\n",
        "**Normalization** - Changing the values of the numerical columns in the dataset to a common scale, without distorting differences in the ranges of values.\n",
        "\n",
        "##Steps to take to train the network:\n",
        "1. Use a **pandas DataFrame** to load in the data (or yahoo finance API depending on what I find to be better).\n",
        "2. Properly define the **Features** and **Labels** so that I know what values to feed into the neural network and what value(s) I should be recieving.\n",
        "3. **Normalize** the dataset so that all numbers encompass the same range but keep the distribution difference (might not need to use the **OneHotEncoder** since there isnt a non numerical column and will only used the **MinMaxScaler** for data **Normalization**).\n",
        "4. Split the dataset up into **Training** and **Testing** datasets, so that the model doesnt just get use to solving the same problems( So that we **Generalize** the neural network).\n",
        "5. Test out different **Optimizers** (mainly **Stochastic Gradient Descent(SGD)** and **Adam**) and experiment with the learning rate(Find the optimal learning rate by plotting the **loss curve**).\n",
        "6. Test out different training lengths (**epochs**).\n",
        "7. Test out creating different amounts of **layers** and **Nuerons**(Maybe try out the **linear activation function** but most likely wont contribute anything to the project).\n",
        "8. Evlaute the performace of the model to keep track of improvement.\n",
        "9. Test the model to make future predictions (Maybe on older values where we know the outcome, then current values and compare them with the true values the next day (does **predictions**==**Actual Values**)).\n",
        "10. Save the model for use in future projects if everything works as expected.\n",
        "\n",
        "###The STONK that shall be analyzed is dodge boi TESLA"
      ],
      "metadata": {
        "id": "hSnyhZa8NN_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSJRKZ3FMRjh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will Be working on 758 clolumns of tesla stock data ranging from the start date of october 15th 2015 to october 15th 2018; Three years of stock data\n",
        "\n",
        "**Columns: date, close, volume, open, high and low**"
      ],
      "metadata": {
        "id": "gFnyzG0UWV3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing the data\n",
        "tesla = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/tesla-stock-price.csv\")\n",
        "tesla.head()\n",
        "#Changes the volume column from string to float\n",
        "tesla[\"volume\"] = tesla[\"volume\"].str.replace(',', '').astype(float)\n",
        "\n",
        "#This will be the features that the model will take in\n",
        "tesla_X = tesla[[\"open\", \"high\", \"low\", \"volume\"]]\n",
        "print(tesla_X)\n",
        "\n",
        "#This will be the labels that the model will try to predict\n",
        "tesla_y = tesla[[\"close\"]]\n",
        "print(tesla_y)\n",
        "\n",
        "tesla_X_train, tesla_X_test, tesla_y_train, tesla_y_test = train_test_split(tesla_X, tesla_y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(tesla_X_train.dtypes)\n",
        "\n",
        "#Create the object that will normalize the data\n",
        "ct = MinMaxScaler()\n",
        "\n",
        "#Normalizes the training and testing data for the features and labels\n",
        "ct.fit(tesla_X_train)\n",
        "tesla_X_train_norm = ct.transform(tesla_X_train)\n",
        "\n",
        "ct.fit(tesla_X_test)\n",
        "tesla_X_test_norm = ct.transform(tesla_X_test)\n",
        "\n",
        "ct.fit(tesla_y_train)\n",
        "tesla_y_train_norm = ct.transform(tesla_y_train)\n",
        "\n",
        "ct.fit(tesla_y_test)\n",
        "tesla_y_test_norm = ct.transform(tesla_y_test)\n",
        "\n",
        "\n",
        "print(f\"this is the data {tesla_X_train_norm}\")\n",
        "print(f\"\\n this is the single point in data {tesla_X_train_norm[0]} and  the shape is {tesla_X_train_norm[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLsNCNXUihW",
        "outputId": "22aa1766-42b9-487f-fa45-47bf876d9c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       open      high       low      volume\n",
            "0    264.50  273.8800  262.2400   4787699.0\n",
            "1    259.06  263.2800  254.5367   6189026.0\n",
            "2    261.00  261.9900  252.0100   7189257.0\n",
            "3    257.53  262.2500  249.0300   8128184.0\n",
            "4    264.61  265.5100  247.7700  12781560.0\n",
            "..      ...       ...       ...         ...\n",
            "752  211.99  214.8100  208.8000   4177956.0\n",
            "753  227.72  228.6000  202.0000  14877020.0\n",
            "754  226.50  231.1500  224.9400   2506836.0\n",
            "755  223.04  230.4805  222.8700   4327574.0\n",
            "756  216.43  221.7300  213.7000   2835920.0\n",
            "\n",
            "[757 rows x 4 columns]\n",
            "      close\n",
            "0    270.49\n",
            "1    259.59\n",
            "2    258.78\n",
            "3    252.23\n",
            "4    256.88\n",
            "..      ...\n",
            "752  210.09\n",
            "753  213.03\n",
            "754  228.10\n",
            "755  227.01\n",
            "756  221.31\n",
            "\n",
            "[757 rows x 1 columns]\n",
            "open      float64\n",
            "high      float64\n",
            "low       float64\n",
            "volume    float64\n",
            "dtype: object\n",
            "this is the data [[0.76985718 0.79470678 0.79863077 0.24341806]\n",
            " [0.74575439 0.7360514  0.75286312 0.26537162]\n",
            " [0.45296067 0.43645585 0.46363521 0.08984735]\n",
            " ...\n",
            " [0.94397839 0.95158115 0.97206609 0.12770029]\n",
            " [0.47055694 0.44105864 0.46803026 0.13485639]\n",
            " [0.59517126 0.56695363 0.55940498 0.25019676]]\n",
            "\n",
            " this is the single point in data [0.76985718 0.79470678 0.79863077 0.24341806] and  the shape is (4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I have prepared the data to be properly passed to the neural network its time to create the neural network and train the model to make predictions on the data."
      ],
      "metadata": {
        "id": "Uw7Z6-kVcviI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the Model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "model.fit(tesla_X_train_norm, tesla_y_train_norm, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hre0-ROwdHCJ",
        "outputId": "5e581448-72e2-45ba-9cc1-c2799926c98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 0.2213 - mae: 0.2213\n",
            "Epoch 2/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0571 - mae: 0.0571\n",
            "Epoch 3/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0698 - mae: 0.0698\n",
            "Epoch 4/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0730 - mae: 0.0730\n",
            "Epoch 5/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0676 - mae: 0.0676\n",
            "Epoch 6/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0679 - mae: 0.0679\n",
            "Epoch 7/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0698 - mae: 0.0698\n",
            "Epoch 8/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0691 - mae: 0.0691\n",
            "Epoch 9/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0659 - mae: 0.0659\n",
            "Epoch 10/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0693 - mae: 0.0693\n",
            "Epoch 11/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0673 - mae: 0.0673\n",
            "Epoch 12/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0637 - mae: 0.0637\n",
            "Epoch 13/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0628 - mae: 0.0628\n",
            "Epoch 14/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0602 - mae: 0.0602\n",
            "Epoch 15/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0646 - mae: 0.0646\n",
            "Epoch 16/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0619 - mae: 0.0619\n",
            "Epoch 17/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0633 - mae: 0.0633\n",
            "Epoch 18/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0606 - mae: 0.0606\n",
            "Epoch 19/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0597 - mae: 0.0597\n",
            "Epoch 20/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0583 - mae: 0.0583\n",
            "Epoch 21/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0545 - mae: 0.0545\n",
            "Epoch 22/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0568 - mae: 0.0568\n",
            "Epoch 23/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0557 - mae: 0.0557\n",
            "Epoch 24/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0544 - mae: 0.0544\n",
            "Epoch 25/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0551 - mae: 0.0551\n",
            "Epoch 26/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0530 - mae: 0.0530\n",
            "Epoch 27/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0544 - mae: 0.0544\n",
            "Epoch 28/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0520 - mae: 0.0520\n",
            "Epoch 29/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0517 - mae: 0.0517\n",
            "Epoch 30/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0511 - mae: 0.0511\n",
            "Epoch 31/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0513 - mae: 0.0513\n",
            "Epoch 32/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0500 - mae: 0.0500\n",
            "Epoch 33/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0507 - mae: 0.0507\n",
            "Epoch 34/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0480 - mae: 0.0480\n",
            "Epoch 35/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0461 - mae: 0.0461\n",
            "Epoch 36/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0470 - mae: 0.0470\n",
            "Epoch 37/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0471 - mae: 0.0471\n",
            "Epoch 38/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0475 - mae: 0.0475\n",
            "Epoch 39/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0454 - mae: 0.0454\n",
            "Epoch 40/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0460\n",
            "Epoch 41/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0426 - mae: 0.0426\n",
            "Epoch 42/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0441 - mae: 0.0441\n",
            "Epoch 43/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0416 - mae: 0.0416\n",
            "Epoch 44/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0423 - mae: 0.0423\n",
            "Epoch 45/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0430 - mae: 0.0430\n",
            "Epoch 46/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0415 - mae: 0.0415\n",
            "Epoch 47/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0425 - mae: 0.0425\n",
            "Epoch 48/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384\n",
            "Epoch 49/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0394 - mae: 0.0394\n",
            "Epoch 50/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0404 - mae: 0.0404\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0374 - mae: 0.0374\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0382 - mae: 0.0382\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0367 - mae: 0.0367\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0397 - mae: 0.0397\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0361 - mae: 0.0361\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0376 - mae: 0.0376\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0364 - mae: 0.0364\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0372 - mae: 0.0372\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0349 - mae: 0.0349\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0381 - mae: 0.0381\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0357 - mae: 0.0357\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0352 - mae: 0.0352\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0345 - mae: 0.0345\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0358 - mae: 0.0358\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0360 - mae: 0.0360\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0338 - mae: 0.0338\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0350 - mae: 0.0350\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.0312\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0349 - mae: 0.0349\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0320 - mae: 0.0320\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0330 - mae: 0.0330\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0322 - mae: 0.0322\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0328 - mae: 0.0328\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0308 - mae: 0.0308\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0320 - mae: 0.0320\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.0307\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0296 - mae: 0.0296\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0297 - mae: 0.0297\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0317 - mae: 0.0317\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0314 - mae: 0.0314\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0302 - mae: 0.0302\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.0298\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0312 - mae: 0.0312\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0298 - mae: 0.0298\n",
            "Epoch 86/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0278 - mae: 0.0278\n",
            "Epoch 87/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 88/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.0288\n",
            "Epoch 89/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 90/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0291 - mae: 0.0291\n",
            "Epoch 91/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 92/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 93/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0282 - mae: 0.0282\n",
            "Epoch 94/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.0260\n",
            "Epoch 95/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0271 - mae: 0.0271\n",
            "Epoch 96/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0265 - mae: 0.0265\n",
            "Epoch 97/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0279 - mae: 0.0279\n",
            "Epoch 98/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 99/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0271 - mae: 0.0271\n",
            "Epoch 100/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.0263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a495d8ea050>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now lets evaluate the models performance and have it perform predictions"
      ],
      "metadata": {
        "id": "0NNxiT7nd9XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the models performance\n",
        "model.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFGgXLM_eEsD",
        "outputId": "d42f427a-ab99-4332-9818-0118ed45e090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - mae: 0.0217\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0216848012059927, 0.0216848012059927]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets perform a prediction with the model"
      ],
      "metadata": {
        "id": "P_WuorYDecBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = model.predict(tesla_X_test_norm)\n",
        "print(y_preds)\n",
        "#print(tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCq-GNmaegxj",
        "outputId": "2b1b6f70-06b0-4d9a-f690-16f44168f942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "[[0.44376698]\n",
            " [0.6141335 ]\n",
            " [0.8905855 ]\n",
            " [0.2351066 ]\n",
            " [0.38756248]\n",
            " [0.8247474 ]\n",
            " [0.63711995]\n",
            " [0.68583286]\n",
            " [0.8423107 ]\n",
            " [0.22538745]\n",
            " [0.7409962 ]\n",
            " [0.3481288 ]\n",
            " [0.31492582]\n",
            " [0.3261777 ]\n",
            " [0.6776508 ]\n",
            " [0.99387985]\n",
            " [0.90933526]\n",
            " [0.2890571 ]\n",
            " [0.6854939 ]\n",
            " [0.269133  ]\n",
            " [0.7555092 ]\n",
            " [0.10012738]\n",
            " [0.44200182]\n",
            " [0.85822046]\n",
            " [0.3035989 ]\n",
            " [0.4463897 ]\n",
            " [0.67094564]\n",
            " [0.73836815]\n",
            " [0.20183063]\n",
            " [0.8448958 ]\n",
            " [0.16108754]\n",
            " [0.45366567]\n",
            " [0.78488827]\n",
            " [0.5813505 ]\n",
            " [0.69832003]\n",
            " [0.26454967]\n",
            " [0.7190632 ]\n",
            " [0.31210026]\n",
            " [0.35872993]\n",
            " [0.36000645]\n",
            " [0.2565409 ]\n",
            " [0.63064843]\n",
            " [0.73057747]\n",
            " [0.8385634 ]\n",
            " [0.27514574]\n",
            " [0.4579083 ]\n",
            " [0.37953347]\n",
            " [0.73687047]\n",
            " [0.2803567 ]\n",
            " [0.3131518 ]\n",
            " [0.7008521 ]\n",
            " [0.29660222]\n",
            " [0.8656379 ]\n",
            " [0.25005305]\n",
            " [0.86088103]\n",
            " [0.16330558]\n",
            " [0.85126984]\n",
            " [0.23339973]\n",
            " [0.03227162]\n",
            " [0.7105383 ]\n",
            " [0.9018708 ]\n",
            " [0.92371565]\n",
            " [0.6726844 ]\n",
            " [0.27875146]\n",
            " [0.4486321 ]\n",
            " [0.505076  ]\n",
            " [0.82368535]\n",
            " [0.84391737]\n",
            " [0.2713715 ]\n",
            " [0.9488963 ]\n",
            " [0.713357  ]\n",
            " [0.3094337 ]\n",
            " [0.3603939 ]\n",
            " [0.7285354 ]\n",
            " [0.3536615 ]\n",
            " [0.87150115]\n",
            " [0.3334553 ]\n",
            " [0.7136829 ]\n",
            " [0.84533983]\n",
            " [0.89191854]\n",
            " [0.15800814]\n",
            " [0.7009621 ]\n",
            " [0.9483035 ]\n",
            " [0.6805338 ]\n",
            " [0.76530284]\n",
            " [0.7600469 ]\n",
            " [0.3823842 ]\n",
            " [0.1902038 ]\n",
            " [0.9595442 ]\n",
            " [0.76440746]\n",
            " [0.83659714]\n",
            " [0.5627809 ]\n",
            " [0.17801407]\n",
            " [0.7823346 ]\n",
            " [0.9212947 ]\n",
            " [0.5316233 ]\n",
            " [0.50142586]\n",
            " [0.6213544 ]\n",
            " [0.42627084]\n",
            " [0.275973  ]\n",
            " [0.6821475 ]\n",
            " [0.73197174]\n",
            " [0.36013487]\n",
            " [0.81336707]\n",
            " [0.79429066]\n",
            " [0.64316803]\n",
            " [0.8964796 ]\n",
            " [0.18726663]\n",
            " [0.47979492]\n",
            " [0.22454453]\n",
            " [0.32734704]\n",
            " [0.63857245]\n",
            " [0.44221628]\n",
            " [0.4016051 ]\n",
            " [0.315072  ]\n",
            " [0.84254646]\n",
            " [0.3236201 ]\n",
            " [0.4782255 ]\n",
            " [0.34005696]\n",
            " [0.43971464]\n",
            " [0.7689896 ]\n",
            " [0.30324897]\n",
            " [0.43138775]\n",
            " [0.86230874]\n",
            " [0.7237483 ]\n",
            " [0.82606274]\n",
            " [0.94925237]\n",
            " [0.94247377]\n",
            " [0.8102123 ]\n",
            " [0.29732037]\n",
            " [0.23571227]\n",
            " [0.22289258]\n",
            " [0.8526615 ]\n",
            " [0.67114246]\n",
            " [0.3659877 ]\n",
            " [0.6301971 ]\n",
            " [0.6977058 ]\n",
            " [0.7093064 ]\n",
            " [0.2197692 ]\n",
            " [1.0298835 ]\n",
            " [0.3476117 ]\n",
            " [0.9848505 ]\n",
            " [0.6663915 ]\n",
            " [0.98535746]\n",
            " [0.44965947]\n",
            " [0.38111624]\n",
            " [0.9508664 ]\n",
            " [0.75971484]\n",
            " [0.23463552]\n",
            " [0.7060465 ]\n",
            " [0.7550514 ]\n",
            " [0.77056795]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction are not quite the same as the true values even thought the mae metrioc is 0.02. Will create a new model with the adam optimizer to see if there is any improvement.\n",
        "\n",
        "Will also train the model for longer and leave the layers alone for this iteration."
      ],
      "metadata": {
        "id": "eCSCosCTgqqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the Model\n",
        "model_2.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. Fit the model\n",
        "history_2 = model_2.fit(tesla_X_train_norm, tesla_y_train_norm, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNy2oGH7g816",
        "outputId": "f02de750-caad-4c5f-d75d-eab80760176a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 1.2727 - mae: 1.2727\n",
            "Epoch 2/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.2075 - mae: 0.2075\n",
            "Epoch 3/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1527 - mae: 0.1527\n",
            "Epoch 4/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0697 - mae: 0.0697\n",
            "Epoch 5/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0354 - mae: 0.0354\n",
            "Epoch 6/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0262 - mae: 0.0262\n",
            "Epoch 7/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0280 - mae: 0.0280\n",
            "Epoch 8/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0254 - mae: 0.0254\n",
            "Epoch 9/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.0287\n",
            "Epoch 10/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0384 - mae: 0.0384\n",
            "Epoch 11/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0381 - mae: 0.0381\n",
            "Epoch 12/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0396 - mae: 0.0396\n",
            "Epoch 13/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 14/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0235 - mae: 0.0235\n",
            "Epoch 15/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0586 - mae: 0.0586\n",
            "Epoch 16/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0572 - mae: 0.0572\n",
            "Epoch 17/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0549 - mae: 0.0549\n",
            "Epoch 18/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0370 - mae: 0.0370\n",
            "Epoch 19/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0410 - mae: 0.0410\n",
            "Epoch 20/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0412 - mae: 0.0412\n",
            "Epoch 21/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0448 - mae: 0.0448\n",
            "Epoch 22/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0485 - mae: 0.0485\n",
            "Epoch 23/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0418 - mae: 0.0418\n",
            "Epoch 24/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0427 - mae: 0.0427\n",
            "Epoch 25/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0262 - mae: 0.0262\n",
            "Epoch 26/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0270 - mae: 0.0270\n",
            "Epoch 27/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 28/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0323 - mae: 0.0323\n",
            "Epoch 29/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0267 - mae: 0.0267\n",
            "Epoch 30/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.0288\n",
            "Epoch 31/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0253 - mae: 0.0253\n",
            "Epoch 32/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 33/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 34/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0185 - mae: 0.0185\n",
            "Epoch 35/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0169\n",
            "Epoch 36/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0196 - mae: 0.0196\n",
            "Epoch 37/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0158\n",
            "Epoch 38/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0165 - mae: 0.0165\n",
            "Epoch 39/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 40/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0185 - mae: 0.0185\n",
            "Epoch 41/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0199\n",
            "Epoch 42/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.0389\n",
            "Epoch 43/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0274 - mae: 0.0274\n",
            "Epoch 44/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0316 - mae: 0.0316\n",
            "Epoch 45/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0254 - mae: 0.0254\n",
            "Epoch 46/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0208 - mae: 0.0208\n",
            "Epoch 47/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0207\n",
            "Epoch 48/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 49/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0277 - mae: 0.0277\n",
            "Epoch 50/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0283 - mae: 0.0283\n",
            "Epoch 51/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0462 - mae: 0.0462\n",
            "Epoch 52/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0403 - mae: 0.0403\n",
            "Epoch 53/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0388 - mae: 0.0388\n",
            "Epoch 54/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0240 - mae: 0.0240\n",
            "Epoch 55/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 56/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0199 - mae: 0.0199\n",
            "Epoch 57/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 58/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.0244\n",
            "Epoch 59/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0218 - mae: 0.0218\n",
            "Epoch 60/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 61/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 62/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0128\n",
            "Epoch 63/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0207 - mae: 0.0207\n",
            "Epoch 64/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 65/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 66/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0145 - mae: 0.0145\n",
            "Epoch 67/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0157 - mae: 0.0157\n",
            "Epoch 68/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 69/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 70/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0233 - mae: 0.0233\n",
            "Epoch 71/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0197\n",
            "Epoch 72/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 73/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0173\n",
            "Epoch 74/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0256 - mae: 0.0256\n",
            "Epoch 75/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0281\n",
            "Epoch 76/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0326 - mae: 0.0326\n",
            "Epoch 77/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0309 - mae: 0.0309\n",
            "Epoch 78/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0580 - mae: 0.0580\n",
            "Epoch 79/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1865 - mae: 0.1865\n",
            "Epoch 80/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.2335 - mae: 0.2335\n",
            "Epoch 81/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.3039 - mae: 0.3039\n",
            "Epoch 82/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1840 - mae: 0.1840\n",
            "Epoch 83/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2983 - mae: 0.2983\n",
            "Epoch 84/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2778 - mae: 0.2778\n",
            "Epoch 85/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.1576 - mae: 0.1576\n",
            "Epoch 86/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1888 - mae: 0.1888\n",
            "Epoch 87/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0996 - mae: 0.0996\n",
            "Epoch 88/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0877 - mae: 0.0877\n",
            "Epoch 89/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0690 - mae: 0.0690\n",
            "Epoch 90/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0607 - mae: 0.0607\n",
            "Epoch 91/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0563 - mae: 0.0563\n",
            "Epoch 92/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0340 - mae: 0.0340\n",
            "Epoch 93/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0289 - mae: 0.0289\n",
            "Epoch 94/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0213 - mae: 0.0213\n",
            "Epoch 95/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.0191\n",
            "Epoch 96/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0266 - mae: 0.0266\n",
            "Epoch 97/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0142 - mae: 0.0142\n",
            "Epoch 98/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 99/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0193 - mae: 0.0193\n",
            "Epoch 100/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0183\n",
            "Epoch 101/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 102/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0255 - mae: 0.0255\n",
            "Epoch 103/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 104/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0146\n",
            "Epoch 105/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 106/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 107/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 108/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.0226\n",
            "Epoch 109/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0215 - mae: 0.0215\n",
            "Epoch 110/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0263 - mae: 0.0263\n",
            "Epoch 111/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0186\n",
            "Epoch 112/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0174 - mae: 0.0174\n",
            "Epoch 113/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0147 - mae: 0.0147\n",
            "Epoch 114/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0134\n",
            "Epoch 115/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0166 - mae: 0.0166\n",
            "Epoch 116/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 117/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0248 - mae: 0.0248\n",
            "Epoch 118/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 119/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0229 - mae: 0.0229\n",
            "Epoch 120/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0182\n",
            "Epoch 121/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0260 - mae: 0.0260\n",
            "Epoch 122/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0236 - mae: 0.0236\n",
            "Epoch 123/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0327 - mae: 0.0327\n",
            "Epoch 124/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 125/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0161\n",
            "Epoch 126/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.0213\n",
            "Epoch 127/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 128/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0139 - mae: 0.0139\n",
            "Epoch 129/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0127 - mae: 0.0127\n",
            "Epoch 130/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 131/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 132/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 133/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 134/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0264 - mae: 0.0264\n",
            "Epoch 135/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0204 - mae: 0.0204\n",
            "Epoch 136/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0235 - mae: 0.0235\n",
            "Epoch 137/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 138/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.0246\n",
            "Epoch 139/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0200 - mae: 0.0200\n",
            "Epoch 140/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0233 - mae: 0.0233\n",
            "Epoch 141/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 142/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0164\n",
            "Epoch 143/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0169 - mae: 0.0169\n",
            "Epoch 144/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0191 - mae: 0.0191\n",
            "Epoch 145/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0190\n",
            "Epoch 146/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0351 - mae: 0.0351\n",
            "Epoch 147/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0563 - mae: 0.0563\n",
            "Epoch 148/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.0411\n",
            "Epoch 149/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0597 - mae: 0.0597\n",
            "Epoch 150/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0697 - mae: 0.0697\n",
            "Epoch 151/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1497 - mae: 0.1497\n",
            "Epoch 152/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2422 - mae: 0.2422\n",
            "Epoch 153/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3245 - mae: 0.3245\n",
            "Epoch 154/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6365 - mae: 0.6365\n",
            "Epoch 155/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5483 - mae: 0.5483\n",
            "Epoch 156/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.8376 - mae: 0.8376\n",
            "Epoch 157/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6303 - mae: 0.6303\n",
            "Epoch 158/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 3.0833 - mae: 3.0833\n",
            "Epoch 159/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 19.0230 - mae: 19.0230\n",
            "Epoch 160/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 15.2821 - mae: 15.2821\n",
            "Epoch 161/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 2.3267 - mae: 2.3267\n",
            "Epoch 162/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.4848 - mae: 1.4848\n",
            "Epoch 163/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5050 - mae: 0.5050\n",
            "Epoch 164/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2456 - mae: 0.2456\n",
            "Epoch 165/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0655 - mae: 0.0655\n",
            "Epoch 166/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.0492\n",
            "Epoch 167/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0430 - mae: 0.0430\n",
            "Epoch 168/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0506 - mae: 0.0506\n",
            "Epoch 169/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0203 - mae: 0.0203\n",
            "Epoch 170/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0258 - mae: 0.0258\n",
            "Epoch 171/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.0245\n",
            "Epoch 172/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 173/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0135\n",
            "Epoch 174/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0184 - mae: 0.0184\n",
            "Epoch 175/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0153 - mae: 0.0153\n",
            "Epoch 176/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 177/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0120\n",
            "Epoch 178/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0151\n",
            "Epoch 179/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.0252\n",
            "Epoch 180/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0269 - mae: 0.0269\n",
            "Epoch 181/200\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.0331\n",
            "Epoch 182/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0226 - mae: 0.0226\n",
            "Epoch 183/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0137 - mae: 0.0137\n",
            "Epoch 184/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0190 - mae: 0.0190\n",
            "Epoch 185/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0313 - mae: 0.0313\n",
            "Epoch 186/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0228 - mae: 0.0228\n",
            "Epoch 187/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0160\n",
            "Epoch 188/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0188 - mae: 0.0188\n",
            "Epoch 189/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0224 - mae: 0.0224\n",
            "Epoch 190/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0170 - mae: 0.0170\n",
            "Epoch 191/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.0195\n",
            "Epoch 192/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0180 - mae: 0.0180\n",
            "Epoch 193/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0136\n",
            "Epoch 194/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0201 - mae: 0.0201\n",
            "Epoch 195/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0205 - mae: 0.0205\n",
            "Epoch 196/200\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 197/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.0283\n",
            "Epoch 198/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0140 - mae: 0.0140\n",
            "Epoch 199/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0173 - mae: 0.0173\n",
            "Epoch 200/200\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juBs2GT2hTt3",
        "outputId": "de340740-f930-4a5d-b0e8-f01a55704282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012555108405649662, 0.012555108405649662]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_2 = model_2.predict(tesla_X_test_norm)\n",
        "#un-normalizes the output values\n",
        "y_preds_2_unnorm = ct.inverse_transform(model_2.predict(tesla_X_test_norm))\n",
        "#print(y_preds_2 == tesla_y_test_norm )\n",
        "print(y_preds_2_unnorm)\n",
        "print( tesla_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oBMl5n8hhLq",
        "outputId": "28442179-0f70-4cd8-ae48-99a95ddb6172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "[[252.64156]\n",
            " [293.9004 ]\n",
            " [351.95917]\n",
            " [205.13486]\n",
            " [240.53825]\n",
            " [337.1643 ]\n",
            " [297.21368]\n",
            " [304.79947]\n",
            " [335.00867]\n",
            " [201.25069]\n",
            " [323.58282]\n",
            " [233.67511]\n",
            " [222.38356]\n",
            " [225.71855]\n",
            " [306.83957]\n",
            " [376.20306]\n",
            " [360.81897]\n",
            " [216.04971]\n",
            " [306.13477]\n",
            " [212.97069]\n",
            " [325.78876]\n",
            " [174.17554]\n",
            " [253.34697]\n",
            " [344.38947]\n",
            " [218.98557]\n",
            " [252.82784]\n",
            " [306.84378]\n",
            " [318.06308]\n",
            " [196.91771]\n",
            " [344.83026]\n",
            " [189.33182]\n",
            " [253.3211 ]\n",
            " [330.919  ]\n",
            " [285.09018]\n",
            " [311.80948]\n",
            " [208.60725]\n",
            " [312.6906 ]\n",
            " [221.44257]\n",
            " [231.73349]\n",
            " [235.02457]\n",
            " [211.17877]\n",
            " [297.64706]\n",
            " [316.6948 ]\n",
            " [341.88522]\n",
            " [212.16408]\n",
            " [255.10878]\n",
            " [236.21388]\n",
            " [321.816  ]\n",
            " [213.75531]\n",
            " [212.06918]\n",
            " [309.33093]\n",
            " [219.39435]\n",
            " [348.35858]\n",
            " [209.19563]\n",
            " [350.06592]\n",
            " [189.71912]\n",
            " [345.77832]\n",
            " [204.512  ]\n",
            " [159.6236 ]\n",
            " [308.15704]\n",
            " [358.7288 ]\n",
            " [356.57065]\n",
            " [304.6649 ]\n",
            " [215.40062]\n",
            " [252.53099]\n",
            " [262.47818]\n",
            " [339.40237]\n",
            " [338.23822]\n",
            " [212.89348]\n",
            " [368.27896]\n",
            " [313.10358]\n",
            " [221.3158 ]\n",
            " [234.86057]\n",
            " [316.27158]\n",
            " [232.82678]\n",
            " [346.9583 ]\n",
            " [226.26358]\n",
            " [311.1795 ]\n",
            " [347.13565]\n",
            " [356.25598]\n",
            " [187.98401]\n",
            " [304.40442]\n",
            " [369.45026]\n",
            " [307.99612]\n",
            " [324.0246 ]\n",
            " [321.57   ]\n",
            " [237.45535]\n",
            " [194.81906]\n",
            " [378.721  ]\n",
            " [325.2577 ]\n",
            " [344.08902]\n",
            " [279.18097]\n",
            " [190.47816]\n",
            " [328.96823]\n",
            " [362.9121 ]\n",
            " [266.99942]\n",
            " [265.4577 ]\n",
            " [293.99768]\n",
            " [247.31693]\n",
            " [214.0454 ]\n",
            " [306.03812]\n",
            " [315.17142]\n",
            " [234.09383]\n",
            " [332.34744]\n",
            " [333.17212]\n",
            " [299.3249 ]\n",
            " [358.64816]\n",
            " [195.22032]\n",
            " [257.6188 ]\n",
            " [201.5722 ]\n",
            " [226.2629 ]\n",
            " [293.9816 ]\n",
            " [247.74338]\n",
            " [244.53476]\n",
            " [222.32153]\n",
            " [342.99567]\n",
            " [225.18704]\n",
            " [260.66956]\n",
            " [231.03697]\n",
            " [252.89482]\n",
            " [324.679  ]\n",
            " [220.52837]\n",
            " [251.75394]\n",
            " [342.5868 ]\n",
            " [314.94684]\n",
            " [343.29572]\n",
            " [372.29428]\n",
            " [365.9076 ]\n",
            " [337.52353]\n",
            " [218.22606]\n",
            " [203.19115]\n",
            " [202.78258]\n",
            " [343.64822]\n",
            " [302.09845]\n",
            " [236.18996]\n",
            " [291.42426]\n",
            " [309.81894]\n",
            " [312.2092 ]\n",
            " [203.27805]\n",
            " [386.6467 ]\n",
            " [230.01111]\n",
            " [373.8866 ]\n",
            " [300.8959 ]\n",
            " [374.55515]\n",
            " [255.52037]\n",
            " [236.61679]\n",
            " [361.61957]\n",
            " [328.08304]\n",
            " [206.2393 ]\n",
            " [313.8351 ]\n",
            " [324.72055]\n",
            " [326.3514 ]]\n",
            "      close\n",
            "409  251.57\n",
            "97   291.72\n",
            "281  349.59\n",
            "497  202.34\n",
            "440  238.36\n",
            "..      ...\n",
            "213  328.91\n",
            "501  203.56\n",
            "356  313.06\n",
            "90   317.66\n",
            "360  324.81\n",
            "\n",
            "[152 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inversing the predictions i realized that the predicted values are higher than the actual values by 2. After making this discovery i will make the bias more complex and try to remove any biases."
      ],
      "metadata": {
        "id": "-PB3CCitsnZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model, this time with more neurons and an activaton function\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"linear\") # Output layer for regression\n",
        "])\n",
        "\n",
        "#2. Compile the model, Will keep using adam with a learning rate of 0.01\n",
        "model_3.compile(loss= tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "#3. Fit the model to the normalized data\n",
        "model_3.fit(tesla_X_train_norm, tesla_y_train_norm, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTUlB6q_3tgx",
        "outputId": "ab37d76b-2b28-4bf2-bcce-31fe3661ff0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 0.0704 - mae: 0.0704\n",
            "Epoch 2/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0212 - mae: 0.0212\n",
            "Epoch 3/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0167\n",
            "Epoch 4/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 5/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0179\n",
            "Epoch 6/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0327 - mae: 0.0327\n",
            "Epoch 7/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0225 - mae: 0.0225\n",
            "Epoch 8/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 9/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0211 - mae: 0.0211\n",
            "Epoch 10/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0161 - mae: 0.0161\n",
            "Epoch 11/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0148 - mae: 0.0148\n",
            "Epoch 12/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0140\n",
            "Epoch 13/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.0309\n",
            "Epoch 14/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0282 - mae: 0.0282\n",
            "Epoch 15/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0242 - mae: 0.0242\n",
            "Epoch 16/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0183 - mae: 0.0183\n",
            "Epoch 17/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0130\n",
            "Epoch 18/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 19/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0127 - mae: 0.0127\n",
            "Epoch 20/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0141\n",
            "Epoch 21/100\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 22/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 23/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0187 - mae: 0.0187\n",
            "Epoch 24/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.0285\n",
            "Epoch 25/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0181 - mae: 0.0181\n",
            "Epoch 26/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 27/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 28/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0149 - mae: 0.0149\n",
            "Epoch 29/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0128\n",
            "Epoch 30/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0119 - mae: 0.0119\n",
            "Epoch 31/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0160 - mae: 0.0160\n",
            "Epoch 32/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0172 - mae: 0.0172\n",
            "Epoch 33/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 34/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0152\n",
            "Epoch 35/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0167\n",
            "Epoch 36/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0135\n",
            "Epoch 37/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 38/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0133 - mae: 0.0133\n",
            "Epoch 39/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 40/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 41/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0148 - mae: 0.0148\n",
            "Epoch 42/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0178 - mae: 0.0178\n",
            "Epoch 43/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0159 - mae: 0.0159\n",
            "Epoch 44/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0122 - mae: 0.0122\n",
            "Epoch 45/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0136\n",
            "Epoch 46/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 47/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n",
            "Epoch 48/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 49/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0109\n",
            "Epoch 50/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0144 - mae: 0.0144\n",
            "Epoch 51/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0216 - mae: 0.0216\n",
            "Epoch 52/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0122\n",
            "Epoch 53/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0143 - mae: 0.0143\n",
            "Epoch 54/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0123 - mae: 0.0123\n",
            "Epoch 55/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0151 - mae: 0.0151\n",
            "Epoch 56/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0194 - mae: 0.0194\n",
            "Epoch 57/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0158\n",
            "Epoch 58/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 59/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0112 - mae: 0.0112\n",
            "Epoch 60/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0141 - mae: 0.0141\n",
            "Epoch 61/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 62/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 63/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0116 - mae: 0.0116\n",
            "Epoch 64/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0130\n",
            "Epoch 65/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0145 - mae: 0.0145\n",
            "Epoch 66/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0150 - mae: 0.0150\n",
            "Epoch 67/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0107\n",
            "Epoch 68/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0106\n",
            "Epoch 69/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0103\n",
            "Epoch 70/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0154 - mae: 0.0154\n",
            "Epoch 71/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0131 - mae: 0.0131\n",
            "Epoch 72/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0124\n",
            "Epoch 73/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 74/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 75/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0117 - mae: 0.0117\n",
            "Epoch 76/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0105\n",
            "Epoch 77/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0111 - mae: 0.0111\n",
            "Epoch 78/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0186 - mae: 0.0186\n",
            "Epoch 79/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0115\n",
            "Epoch 80/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0162 - mae: 0.0162\n",
            "Epoch 81/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0118 - mae: 0.0118\n",
            "Epoch 82/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0104 - mae: 0.0104\n",
            "Epoch 83/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0134\n",
            "Epoch 84/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0129\n",
            "Epoch 85/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0163 - mae: 0.0163\n",
            "Epoch 86/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 87/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0121 - mae: 0.0121\n",
            "Epoch 88/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 89/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0103\n",
            "Epoch 90/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0132\n",
            "Epoch 91/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0174\n",
            "Epoch 92/100\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0102\n",
            "Epoch 93/100\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0108 - mae: 0.0108\n",
            "Epoch 94/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0125\n",
            "Epoch 95/100\n",
            "19/19 [==============================] - 0s 1ms/step - loss: 0.0114 - mae: 0.0114\n",
            "Epoch 96/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0105\n",
            "Epoch 97/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0110 - mae: 0.0110\n",
            "Epoch 98/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0107\n",
            "Epoch 99/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0109 - mae: 0.0109\n",
            "Epoch 100/100\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a495da58940>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "model_3.evaluate(tesla_X_test_norm, tesla_y_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_08xtjtr52BD",
        "outputId": "eac4ee5f-9956-40e1-a4ca-c0c7784b5a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0126\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012571744620800018, 0.012571744620800018]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_3_unnorm = ct.inverse_transform(model_3.predict(tesla_X_test_norm))\n",
        "\n",
        "print(y_preds_3_unnorm, tesla_y_test)"
      ],
      "metadata": {
        "id": "3WTLP95p6DJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Will see if the model works on current tesla stock data\n",
        "\n",
        "#open->high->low->volume\n",
        "\n",
        "# Initialize the scaler\n",
        "ctx = MinMaxScaler()\n",
        "\n",
        "# Assuming 'train_data' is your training data used to fit the model\n",
        "# It should be a NumPy array or similar structure with shape (num_samples, num_features)\n",
        "# ctx.fit(train_data)\n",
        "ctx.fit(tesla_X_train)\n",
        "# Your prediction data\n",
        "yfin = np.array([236.86, 240.12, 234.90, 92379400]).reshape(1, 4)\n",
        "\n",
        "# Normalize the prediction data using the already fitted scaler\n",
        "yfin_norm = ctx.transform(yfin)\n",
        "\n",
        "# Predict using the model\n",
        "current_pred_norm = model_3.predict(yfin_norm)\n",
        "\n",
        "# Inverse transform the prediction\n",
        "current_pred = ctx.inverse_transform(current_pred_norm)\n",
        "\n",
        "print(f\"This is the current prediction: {current_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "lFJkxqLUBMzJ",
        "outputId": "91f0d617-a97d-456b-c34e-163bafe12bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e49da9e7a0a4>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Inverse transform the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcurrent_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_pred_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This is the current prediction: {current_pred}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.predict(tesla_X_test_norm[1])"
      ],
      "metadata": {
        "id": "JbnU3tZdFRa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Turns out that theres more to take into account were trying to forecast stock performance.\n",
        "The following code is from a tutorila on using Long Short term memory neural networks to predict microsoft stock prices to help gain a better understanding of what it takes to create a nueral network to analyze and predict future stock prices"
      ],
      "metadata": {
        "id": "2eB22viDkK4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "df = pd.read_csv(\"MSFT.csv\")\n",
        "#Discarding all other columns\n",
        "df = df[[\"Date\", \"Close\"]]\n",
        "\n",
        "#rightnow our date is a string so we will need to convert it\n",
        "#This is a function that converts the datetime values to int\n",
        "def str_to_datetime(s):\n",
        "  split = s.split('-')\n",
        "  year, month, day = int(split[0]), int(split[1]), int(split[2])\n",
        "  return datetime.datetime(year=year, month=month, day=day)\n",
        "\n",
        "\n",
        "#Will execute the function oin nevery column in the dataframe\n",
        "df[\"Date\"] = df[\"Date\"].apply(str_to_datetime)\n",
        "#Removes the date column and makes it the index\n",
        "df.index = df.pop(\"Date\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbjxnw0akmGy",
        "outputId": "1496cb6c-41a1-4393-bb0d-563c6a760419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Close\n",
            "Date                  \n",
            "1986-03-13    0.097222\n",
            "1986-03-14    0.100694\n",
            "1986-03-17    0.102431\n",
            "1986-03-18    0.099826\n",
            "1986-03-19    0.098090\n",
            "...                ...\n",
            "2023-12-29  376.040009\n",
            "2024-01-02  370.869995\n",
            "2024-01-03  370.600006\n",
            "2024-01-04  367.940002\n",
            "2024-01-05  367.750000\n",
            "\n",
            "[9531 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot to visdualize the current data\n",
        "plt.plot(df.index, df[\"Close\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "CTkO1GVcoYA1",
        "outputId": "9184dcee-613f-4175-f44d-796b7cf267b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a4959b058a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are using **LSTM** we need to convert this into a supervised problem."
      ],
      "metadata": {
        "id": "gw-uD-yloqj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
        "  first_date = str_to_datetime(first_date_str)\n",
        "  last_date  = str_to_datetime(last_date_str)\n",
        "\n",
        "  target_date = first_date\n",
        "\n",
        "  dates = []\n",
        "  X, Y = [], []\n",
        "\n",
        "  last_time = False\n",
        "  while True:\n",
        "    df_subset = dataframe.loc[:target_date].tail(n+1)\n",
        "\n",
        "    if len(df_subset) != n+1:\n",
        "      print(f'Error: Window of size {n} is too large for date {target_date}')\n",
        "      return\n",
        "\n",
        "    values = df_subset['Close'].to_numpy()\n",
        "    x, y = values[:-1], values[-1]\n",
        "\n",
        "    dates.append(target_date)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "    next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
        "    next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
        "    next_date_str = next_datetime_str.split('T')[0]\n",
        "    year_month_day = next_date_str.split('-')\n",
        "    year, month, day = year_month_day\n",
        "    next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
        "\n",
        "    if last_time:\n",
        "      break\n",
        "\n",
        "    target_date = next_date\n",
        "\n",
        "    if target_date == last_date:\n",
        "      last_time = True\n",
        "\n",
        "  ret_df = pd.DataFrame({})\n",
        "  ret_df['Target Date'] = dates\n",
        "\n",
        "  X = np.array(X)\n",
        "  for i in range(0, n):\n",
        "    X[:, i]\n",
        "    ret_df[f'Target-{n-i}'] = X[:, i]\n",
        "\n",
        "  ret_df['Target'] = Y\n",
        "\n",
        "  return ret_df\n",
        "\n",
        "# Start day second time around: '2021-03-25'\n",
        "windowed_df = df_to_windowed_df(df,\n",
        "                                '2021-03-25',\n",
        "                                '2022-03-23',\n",
        "                                n=3)\n",
        "windowed_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XnWkezsDoxPK",
        "outputId": "b19413cf-7aef-4901-93f7-33dcb7a298e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Target Date    Target-3    Target-2    Target-1      Target\n",
              "0    2021-03-25  235.990005  237.580002  235.460007  232.339996\n",
              "1    2021-03-26  237.580002  235.460007  232.339996  236.479996\n",
              "2    2021-03-29  235.460007  232.339996  236.479996  235.240005\n",
              "3    2021-03-30  232.339996  236.479996  235.240005  231.850006\n",
              "4    2021-03-31  236.479996  235.240005  231.850006  235.770004\n",
              "..          ...         ...         ...         ...         ...\n",
              "247  2022-03-17  276.440002  287.149994  294.390015  295.220001\n",
              "248  2022-03-18  287.149994  294.390015  295.220001  300.429993\n",
              "249  2022-03-21  294.390015  295.220001  300.429993  299.160004\n",
              "250  2022-03-22  295.220001  300.429993  299.160004  304.059998\n",
              "251  2022-03-23  300.429993  299.160004  304.059998  299.489990\n",
              "\n",
              "[252 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cc95884-87ce-446e-bae7-911ecd1c5a27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target Date</th>\n",
              "      <th>Target-3</th>\n",
              "      <th>Target-2</th>\n",
              "      <th>Target-1</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-03-25</td>\n",
              "      <td>235.990005</td>\n",
              "      <td>237.580002</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-03-26</td>\n",
              "      <td>237.580002</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>235.460007</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-03-30</td>\n",
              "      <td>232.339996</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "      <td>231.850006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-03-31</td>\n",
              "      <td>236.479996</td>\n",
              "      <td>235.240005</td>\n",
              "      <td>231.850006</td>\n",
              "      <td>235.770004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>2022-03-17</td>\n",
              "      <td>276.440002</td>\n",
              "      <td>287.149994</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>2022-03-18</td>\n",
              "      <td>287.149994</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>2022-03-21</td>\n",
              "      <td>294.390015</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>2022-03-22</td>\n",
              "      <td>295.220001</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "      <td>304.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>2022-03-23</td>\n",
              "      <td>300.429993</td>\n",
              "      <td>299.160004</td>\n",
              "      <td>304.059998</td>\n",
              "      <td>299.489990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>252 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cc95884-87ce-446e-bae7-911ecd1c5a27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cc95884-87ce-446e-bae7-911ecd1c5a27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cc95884-87ce-446e-bae7-911ecd1c5a27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-702305b6-b291-4183-b9ab-5d41156ee70e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-702305b6-b291-4183-b9ab-5d41156ee70e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-702305b6-b291-4183-b9ab-5d41156ee70e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_11623b7e-2b58-44a7-90ca-3ec3e24484e0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('windowed_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_11623b7e-2b58-44a7-90ca-3ec3e24484e0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('windowed_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtO7nug8pFd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}